# üå§Ô∏è Sistema ETL Incremental PostgreSQL ‚Üí MinIO

Sistema automatizado de extracci√≥n, transformaci√≥n y carga (ETL) que extrae **solo datos nuevos** de PostgreSQL y los almacena en formato Parquet en MinIO (capa Bronce de un Data Lake).

## üìã Descripci√≥n General

Este proyecto implementa un pipeline ETL incremental que:
- ‚úÖ Extrae **solo registros nuevos** de todas las tablas de PostgreSQL
- ‚úÖ Detecta autom√°ticamente **Primary Keys** o columnas de rastreo (timestamps o IDs incrementales)
- ‚úÖ **Valida datos nuevos** antes de procesar (compara √∫ltimo valor vs m√°ximo actual)
- ‚úÖ Guarda datos en formato **Parquet comprimido**
- ‚úÖ Sube archivos a **MinIO** (almacenamiento objeto compatible S3)
- ‚úÖ Mantiene un **control de estado** para evitar duplicados
- ‚úÖ Ejecuta autom√°ticamente cada 10 segundos (configurable)

---

## üèóÔ∏è Arquitectura

```
PostgreSQL (Origen)
    ‚Üì
[procces_data.py] ‚Üí Extracci√≥n incremental
    ‚Üì
Archivos Parquet (/tmp)
    ‚Üì
MinIO (Capa Bronce)
    ‚Üì
meteo-bronze/tabla_nombre/tabla_TIMESTAMP.parquet
```

---

## üìÅ Estructura del Proyecto

```
pruebaMeteorologica/
‚îú‚îÄ‚îÄ procces_data.py        # Script principal de ETL
‚îú‚îÄ‚îÄ run_scheduler.sh       # Scheduler para ejecuci√≥n autom√°tica
‚îú‚îÄ‚îÄ venv_meteo/            # Entorno virtual Python
‚îî‚îÄ‚îÄ README.md              # Este archivo
```

---

## üîß Componentes

### 1Ô∏è‚É£ `procces_data.py` - Script ETL Principal

#### **Funcionalidades principales:**

##### üìå `initialize_control_table(connection)`
Crea la tabla `etl_control` en PostgreSQL para rastrear el estado de cada tabla procesada.

**Estructura de `etl_control`:**
```sql
CREATE TABLE etl_control (
    table_name VARCHAR(255) PRIMARY KEY,     -- Nombre de la tabla
    last_extracted_value VARCHAR(255),       -- √öltimo valor procesado (timestamp o ID)
    last_extracted_at TIMESTAMP,             -- Fecha de √∫ltima extracci√≥n
    tracking_column VARCHAR(255)             -- Columna usada para rastreo
)
```

##### üìå `detect_tracking_column(connection, table_name)`
Detecta autom√°ticamente la mejor columna para rastrear cambios incrementales.

**Prioridad de detecci√≥n:**
1. **Columnas de timestamp:** `created_at`, `updated_at`, `timestamp`, `fecha_registro`, `last_update`, `release_date`
2. **Primary Key real de la base de datos** (consulta metadatos de PostgreSQL - m√©todo m√°s confiable)
3. **Columnas con nombre 'id'** (de tipo INTEGER, SERIAL o NUMERIC)

**Retorna:** `(nombre_columna, tipo)` donde tipo es `'timestamp'` o `'id'`

**Ventaja:** Al usar la PRIMARY KEY real, garantiza que se detecten correctamente IDs como `movie_id`, `person_id`, etc.

##### üìå `get_last_extracted_value(connection, table_name)`
Consulta el √∫ltimo valor extra√≠do de una tabla desde `etl_control`.

**Retorna:** `(√∫ltimo_valor, columna_rastreo)` o `(None, None)` si es la primera extracci√≥n.

##### üìå `update_last_extracted_value(connection, table_name, value, tracking_column)`
Actualiza o inserta el √∫ltimo valor procesado en `etl_control` usando `UPSERT` (INSERT ... ON CONFLICT).

##### üìå `get_max_value_in_table(connection, table_name, tracking_column)`
Obtiene el valor m√°ximo actual en la tabla para la columna de rastreo.

**Uso:** Compara el √∫ltimo valor procesado con el m√°ximo actual para evitar extracciones innecesarias.

##### üìå `process_batch()`
Funci√≥n principal que orquesta todo el proceso ETL.

**Flujo de ejecuci√≥n mejorado:**

1. **Inicializaci√≥n:**
   - Crea tabla `etl_control` si no existe
   - Obtiene lista de todas las tablas de PostgreSQL (excluyendo `etl_control`)

2. **Por cada tabla:**
   ```python
   # 1. Detectar columna de rastreo (prioriza PRIMARY KEY)
   tracking_column, tracking_type = detect_tracking_column(connection, table_name)
   
   # 2. Si no hay columna de rastreo, SALTAMOS la tabla (evita cargas completas repetidas)
   if not tracking_column:
       print("‚ö†Ô∏è SKIPPING: No se detect√≥ columna incremental")
       continue
   
   # 3. Obtener √∫ltimo valor procesado
   last_value, stored_column = get_last_extracted_value(connection, table_name)
   
   # 4. Verificar si hay datos nuevos (optimizaci√≥n clave)
   max_value_in_table = get_max_value_in_table(connection, table_name, tracking_column)
   if last_value >= max_value_in_table:
       print("‚úì No hay datos nuevos")
       continue
   
   # 5. Construir query incremental
   if last_value:
       query = f"SELECT * FROM {table_name} WHERE {tracking_column} > :val"
   else:
       query = f"SELECT * FROM {table_name}"  # Primera carga
   ```

3. **Procesamiento:**
   - Si `df.empty`: No hay datos nuevos ‚Üí **no crea archivo, no gasta recursos**
   - Si hay datos: Guarda en Parquet y sube a MinIO

4. **Actualizaci√≥n de control:**
   - Calcula el valor m√°ximo de la columna de rastreo: `df[tracking_column].max()`
   - Actualiza `etl_control` **solo si la carga a MinIO fue exitosa**

5. **Resumen final:**
   - Muestra total de registros nuevos procesados en el batch

---

### 2Ô∏è‚É£ `run_scheduler.sh` - Scheduler de Ejecuci√≥n

Script Bash que ejecuta el ETL de forma continua en intervalos regulares.

#### **Configuraci√≥n:**

```bash
# --- POSTGRESQL ---
export PG_DB="cine"                    # Nombre de la base de datos
export PG_USER="postgres"              # Usuario PostgreSQL
export PG_PASS="1234"                  # Contrase√±a
export PG_HOST="127.0.0.1"             # IP del servidor

# --- MINIO ---
export MINIO_ALIAS="mi_minio"          # Alias configurado con 'mc alias set'
export MINIO_BUCKET="meteo-bronze"     # Bucket de destino

# --- EJECUCI√ìN ---
PYTHON_SCRIPT="procces_data.py"
PYTHON_VENV="venv_meteo/bin/python"
SLEEP_INTERVAL=10                      # 10 segundos (ajustable seg√∫n necesidad)
```

#### **Flujo de ejecuci√≥n:**

**Nota:** El script `procces_data.py` ahora incluye el bucle interno, por lo que puede ejecutarse directamente:

```python
# Dentro de procces_data.py
if __name__ == "__main__":
    while True:
        process_batch()
        print("Esperando 10 segundos...")
        time.sleep(10)
```

O mediante el script bash tradicional:

```bash
while true; do
    TIMESTAMP=$(date +"%Y-%m-%d %H:%M:%S")
    echo "--- INICIO DE BATCH: $TIMESTAMP ---"
    
    # Ejecutar ETL con Python del entorno virtual
    $PYTHON_VENV $PYTHON_SCRIPT
    
    echo "--- FIN DE BATCH ---"
    echo "Esperando $SLEEP_INTERVAL segundos..."
    sleep $SLEEP_INTERVAL
done
```

**Caracter√≠sticas:**
- ‚úÖ Bucle infinito con intervalo configurable (10 segundos por defecto)
- ‚úÖ Usa el Python del entorno virtual
- ‚úÖ Variables de entorno exportadas para `procces_data.py`
- ‚úÖ Timestamps en cada ejecuci√≥n
- ‚úÖ Detener con `Ctrl+C`
- ‚úÖ **Validaci√≥n previa:** Verifica si hay datos nuevos antes de procesarlos

---

## üöÄ Instalaci√≥n y Configuraci√≥n

### **Requisitos previos:**

1. **PostgreSQL** corriendo con tablas a procesar
2. **MinIO** instalado y configurado
3. **Cliente MinIO (`mc`)** instalado:
   ```bash
   wget https://dl.min.io/client/mc/release/linux-amd64/mc
   chmod +x mc
   sudo mv mc /usr/local/bin/
   ```

### **Paso 1: Clonar y configurar entorno**

```bash
cd /home/andrews/Documentos/pruebaMeteorologica

# Activar entorno virtual
source venv_meteo/bin/activate

# Instalar dependencias (si no est√°n instaladas)
pip install pandas sqlalchemy psycopg2-binary pyarrow
```

### **Paso 2: Configurar MinIO**

```bash
# Configurar alias de MinIO
mc alias set mi_minio http://localhost:9000 minioadmin minioadmin

# Crear bucket
mc mb mi_minio/meteo-bronze

# Verificar conexi√≥n
mc ls mi_minio
```

### **Paso 3: Configurar credenciales**

Editar `run_scheduler.sh` con tus credenciales:

```bash
export PG_DB="tu_base_datos"
export PG_USER="tu_usuario"
export PG_PASS="tu_contrase√±a"
export PG_HOST="ip_servidor_postgres"

export MINIO_ALIAS="mi_minio"
export MINIO_BUCKET="meteo-bronze"
```

### **Paso 4: Dar permisos de ejecuci√≥n**

```bash
chmod +x run_scheduler.sh
```

---

## ‚ñ∂Ô∏è Uso

### **Ejecuci√≥n manual √∫nica:**

```bash
source venv_meteo/bin/activate
python procces_data.py
```

### **Ejecuci√≥n autom√°tica continua:**

```bash
./run_scheduler.sh
```

Esto ejecutar√° el ETL cada **5 minutos** indefinidamente. Para detener, presiona `Ctrl+C`.

### **Cambiar frecuencia de ejecuci√≥n:**

Editar en `run_scheduler.sh`:

```bash
SLEEP_INTERVAL=60    # 1 minuto
SLEEP_INTERVAL=300   # 5 minutos (actual)
SLEEP_INTERVAL=900   # 15 minutos
SLEEP_INTERVAL=3600  # 1 hora
```

---

## üìä Ejemplo de Ejecuci√≥n

### **Primera ejecuci√≥n:**

```
============================================================
Procesando tabla: peliculas
============================================================
üÜï Primera extracci√≥n de peliculas. Extrayendo todos los datos.
üì¶ Registros nuevos encontrados: 150
üíæ Datos guardados localmente: /tmp/peliculas_20251201143025.parquet
‚úÖ Cargado exitosamente a MinIO Bronce: mi_minio/meteo-bronze/peliculas/peliculas_20251201143025.parquet
üîÑ Control actualizado. Nuevo √∫ltimo valor: 2025-12-01 14:30:25

============================================================
üéØ RESUMEN: 150 registros nuevos procesados en total
============================================================
```

### **Segunda ejecuci√≥n (5 minutos despu√©s):**

```
============================================================
Procesando tabla: peliculas
============================================================
üìä Columna de rastreo: created_at
üìÖ √öltimo valor procesado: 2025-12-01 14:30:25
üì¶ Registros nuevos encontrados: 12
üíæ Datos guardados localmente: /tmp/peliculas_20251201143525.parquet
‚úÖ Cargado exitosamente a MinIO Bronce: mi_minio/meteo-bronze/peliculas/peliculas_20251201143525.parquet
üîÑ Control actualizado. Nuevo √∫ltimo valor: 2025-12-01 14:35:20

============================================================
üéØ RESUMEN: 12 registros nuevos procesados en total
============================================================
```

### **Tercera ejecuci√≥n (sin datos nuevos):**

```
============================================================
Procesando tabla: peliculas
============================================================
üìä Columna de rastreo: created_at
üìÖ √öltimo valor procesado: 2025-12-01 14:35:20
‚úì No hay datos nuevos en peliculas.

============================================================
üéØ RESUMEN: 0 registros nuevos procesados en total
============================================================
```

---

## üìÇ Estructura de Archivos en MinIO

```
meteo-bronze/
‚îú‚îÄ‚îÄ peliculas/
‚îÇ   ‚îú‚îÄ‚îÄ peliculas_20251201143025.parquet  (150 registros - primera carga)
‚îÇ   ‚îú‚îÄ‚îÄ peliculas_20251201143525.parquet  (12 registros - solo nuevos)
‚îÇ   ‚îî‚îÄ‚îÄ peliculas_20251201144025.parquet  (8 registros - solo nuevos)
‚îú‚îÄ‚îÄ actores/
‚îÇ   ‚îú‚îÄ‚îÄ actores_20251201143025.parquet
‚îÇ   ‚îî‚îÄ‚îÄ actores_20251201143525.parquet
‚îî‚îÄ‚îÄ directores/
    ‚îî‚îÄ‚îÄ directores_20251201143025.parquet
```

**Cada archivo Parquet contiene SOLO los registros nuevos** desde la √∫ltima extracci√≥n.

---

## üîç Verificaci√≥n de Datos

### **Ver archivos en MinIO:**

```bash
mc ls mi_minio/meteo-bronze/
mc ls mi_minio/meteo-bronze/peliculas/
```

### **Descargar archivo Parquet:**

```bash
mc cp mi_minio/meteo-bronze/peliculas/peliculas_20251201143025.parquet ./
```

### **Leer Parquet con Python:**

```python
import pandas as pd

df = pd.read_parquet('peliculas_20251201143025.parquet')
print(df.head())
print(f"Total registros: {len(df)}")
```

### **Consultar tabla de control en PostgreSQL:**

```sql
SELECT * FROM etl_control;
```

Resultado:
```
table_name  | last_extracted_value    | last_extracted_at       | tracking_column
------------|-------------------------|-------------------------|----------------
peliculas   | 2025-12-01 14:35:20     | 2025-12-01 14:35:30     | created_at
actores     | 2025-12-01 14:35:18     | 2025-12-01 14:35:30     | updated_at
directores  | 523                     | 2025-12-01 14:30:30     | id
```

---

## üõ†Ô∏è Soluci√≥n de Problemas

### **Error: "El cliente 'mc' no est√° instalado"**

```bash
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc
sudo mv mc /usr/local/bin/
mc --version
```

### **Error: "Fall√≥ la carga a MinIO"**

Verificar configuraci√≥n del alias:

```bash
mc alias list
mc alias set mi_minio http://localhost:9000 minioadmin minioadmin
```

### **Error de conexi√≥n a PostgreSQL**

Verificar credenciales en `run_scheduler.sh`:

```bash
psql -h 127.0.0.1 -U postgres -d cine
```

### **No detecta columna de rastreo**

Si tus tablas usan nombres personalizados, edita `detect_tracking_column()` en `procces_data.py`:

```python
timestamp_candidates = ['created_at', 'updated_at', 'timestamp', 'fecha', 'date', 'datetime', 'tu_columna_custom']
```

---

## üìà Optimizaciones Futuras

- [ ] Paralelizaci√≥n de tablas con `multiprocessing`
- [ ] Soporte para particionamiento por fecha en MinIO
- [ ] Compresi√≥n adicional con Snappy/GZIP
- [ ] Integraci√≥n con Apache Airflow
- [ ] M√©tricas y alertas con Prometheus/Grafana
- [ ] Soporte para CDC (Change Data Capture) con Debezium

---

## üìù Notas Importantes

1. **L√≠mite de seguridad:** Por defecto extrae m√°ximo 10,000 filas por tabla por ejecuci√≥n (ajustable en el c√≥digo).

2. **Archivos incrementales:** Cada Parquet contiene SOLO datos nuevos. Para an√°lisis, deber√°s unir todos los archivos de una tabla.

3. **Primera ejecuci√≥n lenta:** La primera vez extrae todos los datos. Las siguientes solo incrementales.

4. **Tablas sin rastreo:** Si una tabla no tiene timestamp ni ID incremental, se extraen todos los datos en cada ejecuci√≥n.

---

## üë§ Autor

Sistema desarrollado para procesamiento ETL incremental de datos meteorol√≥gicos con arquitectura Data Lake.

---

## üìÑ Licencia

Este proyecto es de uso interno para procesamiento de datos.
