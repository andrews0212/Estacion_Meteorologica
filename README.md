# ğŸŒ¤ï¸ Sistema ETL Incremental PostgreSQL â†’ MinIO

Sistema automatizado de extracciÃ³n, transformaciÃ³n y carga (ETL) que extrae **solo datos nuevos** de PostgreSQL y los almacena en formato Parquet en MinIO (capa Bronce de un Data Lake).

## ğŸ“‹ DescripciÃ³n General

Este proyecto implementa un pipeline ETL incremental con **arquitectura modular orientada a objetos** que:
- âœ… Extrae **solo registros nuevos** de todas las tablas de PostgreSQL
- âœ… Detecta automÃ¡ticamente **Primary Keys** o columnas de rastreo (timestamps o IDs incrementales)
- âœ… **Valida datos nuevos** antes de procesar (compara Ãºltimo valor vs mÃ¡ximo actual)
- âœ… Guarda datos en formato **Parquet comprimido**
- âœ… Sube archivos a **MinIO** (almacenamiento objeto compatible S3)
- âœ… Mantiene un **control de estado** para evitar duplicados
- âœ… Ejecuta automÃ¡ticamente cada 10 segundos (configurable)
- âœ… **CÃ³digo modular**: cada componente en su propio archivo
- âœ… **FÃ¡cil mantenimiento**: estructura clara y comentada

---

## ğŸ—ï¸ Arquitectura

```
PostgreSQL (Origen)
    â†“
[ETLPipeline] â†’ ExtracciÃ³n incremental
    â†“
Archivos Parquet (/tmp)
    â†“
MinIO (Capa Bronce)
    â†“
meteo-bronze/tabla_nombre/tabla_TIMESTAMP.parquet
```

---

## ğŸ“ Estructura del Proyecto (Modular OOP)

```
pruebaMeteorologica/
â”œâ”€â”€ main.py                          # ğŸš€ Punto de entrada principal
â”œâ”€â”€ run_scheduler.sh                 # Script Bash para ejecutar el sistema
â”œâ”€â”€ README.md                        # DocumentaciÃ³n completa
â”œâ”€â”€ config/                          # ğŸ“ Configuraciones
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database_config.py          # ConfiguraciÃ³n de PostgreSQL
â”‚   â””â”€â”€ minio_config.py             # ConfiguraciÃ³n de MinIO
â”œâ”€â”€ etl/                             # ğŸ”§ Componentes del pipeline ETL
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ control_manager.py          # GestiÃ³n de tabla de control
â”‚   â”œâ”€â”€ table_inspector.py          # InspecciÃ³n de estructura de tablas
â”‚   â”œâ”€â”€ data_extractor.py           # ExtracciÃ³n incremental de datos
â”‚   â”œâ”€â”€ parquet_writer.py           # Escritura de archivos Parquet
â”‚   â”œâ”€â”€ minio_uploader.py           # Subida de archivos a MinIO
â”‚   â”œâ”€â”€ table_processor.py          # Procesamiento de tabla individual
â”‚   â””â”€â”€ pipeline.py                 # Pipeline completo del ETL
â””â”€â”€ venv_meteo/                      # Entorno virtual Python
```

### **ğŸ¯ Ventajas de la estructura modular:**

1. **SeparaciÃ³n de responsabilidades**: Cada clase tiene una funciÃ³n especÃ­fica
2. **ReutilizaciÃ³n**: Puedes importar componentes individualmente
3. **Testing**: Facilita pruebas unitarias por componente
4. **Mantenibilidad**: FÃ¡cil localizar y modificar funcionalidades
5. **Escalabilidad**: Agregar nuevas features sin tocar cÃ³digo existente
6. **Legibilidad**: CÃ³digo organizado y bien documentado

---

## ğŸ”§ Componentes del Sistema

### 1ï¸âƒ£ **MÃ³dulo `config/` - Configuraciones**

#### **`DatabaseConfig`** (database_config.py)
Clase que encapsula la configuraciÃ³n de PostgreSQL leyendo variables de entorno.

**Propiedades:**
- `user`: Usuario de PostgreSQL
- `password`: ContraseÃ±a
- `host`: IP del servidor
- `database`: Nombre de la base de datos
- `connection_url`: URL de conexiÃ³n formateada

#### **`MinIOConfig`** (minio_config.py)
Clase que encapsula la configuraciÃ³n de MinIO.

**Propiedades:**
- `alias`: Alias configurado con `mc alias set`
- `bucket`: Nombre del bucket de destino

---

### 2ï¸âƒ£ **MÃ³dulo `etl/` - Pipeline ETL**

#### **`ETLControlManager`** (control_manager.py)
Gestiona la tabla `etl_control` que rastrea el estado de extracciÃ³n de cada tabla.

**MÃ©todos:**
- `initialize_table()`: Crea la tabla de control si no existe
- `get_last_extracted_value(table_name)`: Obtiene el Ãºltimo valor extraÃ­do
- `update_last_extracted_value(table_name, value, column)`: Actualiza usando UPSERT

**Estructura de `etl_control`:**
```sql
CREATE TABLE etl_control (
    table_name VARCHAR(255) PRIMARY KEY,
    last_extracted_value VARCHAR(255),
    last_extracted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    tracking_column VARCHAR(255)
)
```

#### **`TableInspector`** (table_inspector.py)
Inspecciona la estructura de las tablas de PostgreSQL.

**MÃ©todos:**
- `get_all_tables()`: Lista todas las tablas (excepto etl_control)
- `get_columns(table_name)`: Obtiene columnas con sus tipos
- `detect_tracking_column(table_name)`: Detecta la mejor columna para rastreo

**Prioridad de detecciÃ³n:**
1. Columnas de timestamp (`created_at`, `updated_at`, etc.)
2. PRIMARY KEY numÃ©rica (consulta metadatos PostgreSQL)
3. Columna llamada 'id' genÃ©rica

#### **`DataExtractor`** (data_extractor.py)
Extrae datos incrementales de PostgreSQL.

**MÃ©todos:**
- `extract_incremental(last_value)`: Extrae solo datos nuevos

**LÃ³gica:**
- Si `last_value` existe: `SELECT * WHERE columna > last_value`
- Si es primera carga: `SELECT * FROM tabla`

#### **`ParquetWriter`** (parquet_writer.py)
Gestiona la escritura de archivos Parquet.

**MÃ©todos:**
- `write(dataframe)`: Guarda DataFrame en formato Parquet
- `cleanup()`: Elimina archivo temporal

#### **`MinIOUploader`** (minio_uploader.py)
Gestiona la subida de archivos a MinIO.

**MÃ©todos:**
- `upload(local_path, table_name, file_name)`: Sube archivo usando cliente `mc`

#### **`TableProcessor`** (table_processor.py)
Orquesta el procesamiento completo de una tabla.

**Flujo:**
1. Detecta columna de rastreo
2. Obtiene Ãºltimo valor procesado
3. Extrae datos nuevos
4. Guarda en Parquet
5. Sube a MinIO
6. Actualiza control

**Retorna:** Cantidad de registros procesados

#### **`ETLPipeline`** (pipeline.py)
Pipeline principal que coordina todo el ETL.

**MÃ©todos:**
- `process_batch()`: Procesa un batch completo de todas las tablas
- `run_continuous(interval_seconds)`: Ejecuta el ETL en bucle infinito

---

### 3ï¸âƒ£ **`main.py` - Punto de Entrada**

Script principal que inicializa y ejecuta el sistema ETL.

**Funcionalidad:**
- Carga configuraciones (DB y MinIO)
- Crea instancia del pipeline
- Ejecuta en modo continuo con intervalo de 10 segundos
- Maneja interrupciÃ³n con Ctrl+C

---

### 4ï¸âƒ£ **`run_scheduler.sh` - Script de EjecuciÃ³n**

Script Bash que ejecuta el ETL de forma continua en intervalos regulares.

Script Bash que configura variables de entorno y ejecuta `main.py`.

#### **ConfiguraciÃ³n:**

```bash
# --- POSTGRESQL ---
export PG_DB="cine"
export PG_USER="postgres"
export PG_PASS="1234"
export PG_HOST="127.0.0.1"

# --- MINIO ---
export MINIO_ALIAS="mi_minio"
export MINIO_BUCKET="meteo-bronze"

# --- EJECUCIÃ“N ---
PYTHON_SCRIPT="main.py"
PYTHON_VENV="venv_meteo/bin/python"
```

**CaracterÃ­sticas:**
- âœ… Exporta variables de entorno
- âœ… Usa Python del entorno virtual
- âœ… Ejecuta `main.py` que contiene el bucle infinito
- âœ… Detener con `Ctrl+C`

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### **Requisitos previos:**

1. **PostgreSQL** corriendo con tablas a procesar
2. **MinIO** instalado y configurado
3. **Cliente MinIO (`mc`)** instalado:
   ```bash
   wget https://dl.min.io/client/mc/release/linux-amd64/mc
   chmod +x mc
   sudo mv mc /usr/local/bin/
   ```

### **Paso 1: Clonar y configurar entorno**

```bash
cd /home/andrews/Documentos/pruebaMeteorologica

# Activar entorno virtual
source venv_meteo/bin/activate

# Instalar dependencias (si no estÃ¡n instaladas)
pip install pandas sqlalchemy psycopg2-binary pyarrow
```

### **Paso 2: Configurar MinIO**

```bash
# Configurar alias de MinIO
mc alias set mi_minio http://localhost:9000 minioadmin minioadmin

# Crear bucket
mc mb mi_minio/meteo-bronze

# Verificar conexiÃ³n
mc ls mi_minio
```

### **Paso 3: Configurar credenciales**

Editar `run_scheduler.sh` con tus credenciales:

```bash
export PG_DB="tu_base_datos"
export PG_USER="tu_usuario"
export PG_PASS="tu_contraseÃ±a"
export PG_HOST="ip_servidor_postgres"

export MINIO_ALIAS="mi_minio"
export MINIO_BUCKET="meteo-bronze"
```

### **Paso 4: Dar permisos de ejecuciÃ³n**

```bash
chmod +x run_scheduler.sh
```

---

## â–¶ï¸ Uso

### **EjecuciÃ³n recomendada (con script bash):**

```bash
./run_scheduler.sh
```

### **EjecuciÃ³n manual con Python:**

```bash
# Exportar variables de entorno
export PG_DB="cine" PG_USER="postgres" PG_PASS="1234" PG_HOST="127.0.0.1"
export MINIO_ALIAS="mi_minio" MINIO_BUCKET="meteo-bronze"

# Activar entorno virtual y ejecutar
source venv_meteo/bin/activate
python main.py
```

El sistema ejecutarÃ¡ el ETL cada **10 segundos** indefinidamente. Para detener, presiona `Ctrl+C`.

### **Cambiar frecuencia de ejecuciÃ³n:**

Editar en `main.py` la funciÃ³n `main()`:

```python
# Cambiar el intervalo (en segundos)
pipeline.run_continuous(interval_seconds=10)   # 10 segundos (actual)
pipeline.run_continuous(interval_seconds=60)   # 1 minuto
pipeline.run_continuous(interval_seconds=300)  # 5 minutos
```

---

## ğŸ“Š Ejemplo de EjecuciÃ³n

### **Primera ejecuciÃ³n:**

```
ğŸš€ Iniciando Sistema ETL Incremental
============================================================
ğŸ“Š Base de datos: cine@127.0.0.1
ğŸ—„ï¸  MinIO Bucket: meteo-bronze
============================================================

--- INICIO DE BATCH: 2025-12-01 23:10:15 ---

Procesando tabla: movie
   ğŸ†• Carga Inicial (movie_id)
   ğŸ“¦ Registros nuevos: 3
   âœ… Subido a MinIO: movie_20251201231015.parquet

Procesando tabla: person
   ğŸ†• Carga Inicial (person_id)
   ğŸ“¦ Registros nuevos: 9
   âœ… Subido a MinIO: person_20251201231015.parquet

ğŸ¯ RESUMEN: 12 registros nuevos en este batch.
Esperando 10 segundos...
```

### **Segunda ejecuciÃ³n (10 segundos despuÃ©s - sin cambios):**

```
--- INICIO DE BATCH: 2025-12-01 23:10:25 ---

Procesando tabla: movie
   âœ“ No hay datos nuevos.

Procesando tabla: person
   âœ“ No hay datos nuevos.

ğŸ¯ RESUMEN: 0 registros nuevos en este batch.
Esperando 10 segundos...
```

### **Tercera ejecuciÃ³n (despuÃ©s de insertar 2 pelÃ­culas nuevas):**

```
--- INICIO DE BATCH: 2025-12-01 23:10:35 ---

Procesando tabla: movie
   ğŸ“Š Incremental (movie_id) > 3
   ğŸ“¦ Registros nuevos: 2
   âœ… Subido a MinIO: movie_20251201231035.parquet

Procesando tabla: person
   âœ“ No hay datos nuevos.

ğŸ¯ RESUMEN: 2 registros nuevos en este batch.
Esperando 10 segundos...
```

---

## ğŸ“‚ Estructura de Archivos en MinIO

```
meteo-bronze/
â”œâ”€â”€ movie/
â”‚   â”œâ”€â”€ movie_20251201231015.parquet  (3 registros - primera carga)
â”‚   â”œâ”€â”€ movie_20251201231035.parquet  (2 registros - solo nuevos)
â”‚   â””â”€â”€ movie_20251202081525.parquet  (1 registro - solo nuevo)
â”œâ”€â”€ person/
â”‚   â”œâ”€â”€ person_20251201231015.parquet  (9 registros - primera carga)
â”‚   â””â”€â”€ person_20251202091035.parquet  (4 registros - solo nuevos)
â”œâ”€â”€ genre/
â”‚   â””â”€â”€ genre_20251201231015.parquet  (5 registros - primera carga)
â””â”€â”€ keyword/
    â””â”€â”€ keyword_20251201231015.parquet  (120 registros - primera carga)
```

**Cada archivo Parquet contiene SOLO los registros nuevos** desde la Ãºltima extracciÃ³n. La estructura de carpetas replica los nombres de las tablas de PostgreSQL.

---

## ğŸ” VerificaciÃ³n de Datos

### **Ver archivos en MinIO:**

```bash
mc ls mi_minio/meteo-bronze/
mc ls mi_minio/meteo-bronze/movie/
```

### **Descargar archivo Parquet:**

```bash
mc cp mi_minio/meteo-bronze/movie/movie_20251201231015.parquet ./
```

### **Leer Parquet con Python:**

```python
import pandas as pd

df = pd.read_parquet('movie_20251201231015.parquet')
print(df.head())
print(f"Total registros: {len(df)}")
print(df.columns.tolist())  # Ver columnas
```

### **Consultar tabla de control en PostgreSQL:**

```sql
SELECT * FROM etl_control;
```

Resultado:
```
table_name  | last_extracted_value    | last_extracted_at       | tracking_column
------------|-------------------------|-------------------------|----------------
movie       | 5                       | 2025-12-01 23:10:35     | movie_id
person      | 9                       | 2025-12-01 23:10:15     | person_id
genre       | 5                       | 2025-12-01 23:10:15     | genre_id
keyword     | 120                     | 2025-12-01 23:10:15     | keyword_id
```

---

## ğŸ› ï¸ SoluciÃ³n de Problemas

### **Error: "El cliente 'mc' no estÃ¡ instalado"**

```bash
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc
sudo mv mc /usr/local/bin/
mc --version
```

### **Error: "FallÃ³ la carga a MinIO"**

Verificar configuraciÃ³n del alias:

```bash
mc alias list
mc alias set mi_minio http://localhost:9000 minioadmin minioadmin
```

### **Error de conexiÃ³n a PostgreSQL**

Verificar credenciales en `run_scheduler.sh`:

```bash
psql -h 127.0.0.1 -U postgres -d cine
```

### **No detecta columna de rastreo**

El sistema automÃ¡ticamente detecta columnas de rastreo en este orden:
1. **Columnas timestamp:** `created_at`, `updated_at`, `timestamp`, `fecha`
2. **PRIMARY KEY numÃ©rico:** Detectado desde metadatos de PostgreSQL
3. **Columna 'id':** Si existe y es numÃ©rica

Si tus tablas usan nombres personalizados, edita `detect_tracking_column()` en `etl/table_inspector.py`:

```python
timestamp_candidates = ['created_at', 'updated_at', 'timestamp', 'fecha', 'date', 'datetime', 'tu_columna_custom']
```

---

## ğŸ“ˆ Optimizaciones Futuras

- [ ] ParalelizaciÃ³n de tablas con `multiprocessing`
- [ ] Soporte para particionamiento por fecha en MinIO
- [ ] CompresiÃ³n adicional con Snappy/GZIP
- [ ] IntegraciÃ³n con Apache Airflow
- [ ] MÃ©tricas y alertas con Prometheus/Grafana
- [ ] Soporte para CDC (Change Data Capture) con Debezium

---

## ğŸ“ Notas Importantes

1. **LÃ­mite de seguridad:** Por defecto extrae mÃ¡ximo 10,000 filas por tabla por ejecuciÃ³n (ajustable en `etl/data_extractor.py`).

2. **Archivos incrementales:** Cada Parquet contiene SOLO datos nuevos. Para anÃ¡lisis, deberÃ¡s unir todos los archivos de una tabla.

3. **Primera ejecuciÃ³n lenta:** La primera vez extrae todos los datos. Las siguientes solo incrementales.

4. **Tablas sin rastreo:** Si una tabla no tiene timestamp ni PRIMARY KEY numÃ©rico, serÃ¡ **OMITIDA** (no se procesarÃ¡).

5. **ValidaciÃ³n automÃ¡tica:** El sistema compara el Ãºltimo valor procesado con el mÃ¡ximo actual en la tabla antes de extraer datos. Si no hay cambios, omite la extracciÃ³n.

6. **Arquitectura OOP:** El cÃ³digo estÃ¡ organizado en mÃ³dulos (`config/` y `etl/`) siguiendo principios de programaciÃ³n orientada a objetos para facilitar mantenimiento y extensiÃ³n.

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL  â”‚  (Base de datos cine)
â”‚   (cine)    â”‚  â† Tablas: movie, person, genre, keyword...
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 1. SQLAlchemy extrae datos incrementales
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Sistema ETL (Python OOP)               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ETLControlManager: Rastrea Ãºltimo valor    â”‚ â”‚
â”‚ â”‚ TableInspector: Detecta PRIMARY KEYs       â”‚ â”‚
â”‚ â”‚ DataExtractor: Extrae solo datos nuevos    â”‚ â”‚
â”‚ â”‚ ParquetWriter: Genera archivos .parquet    â”‚ â”‚
â”‚ â”‚ MinIOUploader: Sube a object storage       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 2. Archivos Parquet comprimidos
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MinIO     â”‚  (Object Storage - Capa Bronze)
â”‚   Bucket:   â”‚  â† Estructura: meteo-bronze/tabla/archivo.parquet
â”‚ meteo-bronzeâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Flujo completo:**
1. El sistema consulta PostgreSQL cada 10 segundos
2. Detecta PRIMARY KEY o timestamp de cada tabla
3. Compara Ãºltimo valor procesado vs mÃ¡ximo actual
4. Si hay datos nuevos: extrae â†’ convierte a Parquet â†’ sube a MinIO
5. Si no hay cambios: omite procesamiento
6. Actualiza tabla de control con nuevo Ãºltimo valor

---

## ğŸ‘¤ Autor

Sistema desarrollado para procesamiento ETL incremental de base de datos de cine con arquitectura Data Lake.

---

## ğŸ“„ Licencia

Este proyecto es de uso interno para procesamiento de datos.
