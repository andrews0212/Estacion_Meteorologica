# ğŸŒ¤ï¸ Sistema ETL Incremental PostgreSQL â†’ MinIO (Bronce-Silver)

Sistema automatizado de extracciÃ³n, transformaciÃ³n y carga (ETL) que extrae **solo datos nuevos** de PostgreSQL, los almacena en MinIO (capa Bronce) y automÃ¡ticamente los **limpia y consolida** en una Ãºnica capa Silver.

**CaracterÃ­sticas principales:**
- âœ… ExtracciÃ³n incremental desde PostgreSQL
- âœ… Limpieza automÃ¡tica (Bronce â†’ Silver)
- âœ… ConsolidaciÃ³n en archivo Ãºnico por tabla
- âœ… Estrategia REPLACE: mantiene solo la versiÃ³n mÃ¡s reciente
- âœ… Arquitectura modular OOP
- âœ… EjecuciÃ³n automÃ¡tica cada 5 minutos

---

## ğŸ“‹ Contenido

1. [DescripciÃ³n General](#descripciÃ³n-general)
2. [Arquitectura y Flujo](#arquitectura-y-flujo)
3. [InstalaciÃ³n y ConfiguraciÃ³n](#instalaciÃ³n-y-configuraciÃ³n)
4. [Uso y EjecuciÃ³n](#uso-y-ejecuciÃ³n)
5. [Estructura del CÃ³digo](#estructura-del-cÃ³digo)
6. [Capa Bronce](#capa-bronce)
7. [Capa Silver](#capa-silver)
8. [Limpieza AutomÃ¡tica](#limpieza-automÃ¡tica)
9. [SoluciÃ³n de Problemas](#soluciÃ³n-de-problemas)

---

## ğŸ“‹ DescripciÃ³n General

### Â¿QuÃ© hace?

```
PostgreSQL
    â†“
[ExtracciÃ³n Incremental]
    â†“
MinIO Bronce (CSV crudos)
    â†“
[Limpieza AutomÃ¡tica]
    â†“
MinIO Silver (CSV consolidado + limpio)
```

### Flujo de Datos AutomÃ¡tico

**Ciclo completo cada 5 minutos:**

1. **ExtracciÃ³n** (2-3 seg)
   - Detecta columnas de rastreo
   - Extrae solo registros nuevos
   - Guarda en MinIO Bronce (CSV)

2. **Limpieza** (1-2 seg)
   - Descarga todos los CSV de Bronce
   - Los combina en un Ãºnico DataFrame
   - Aplica reglas de limpieza
   - Guarda en MinIO Silver (CSV Ãºnico)
   - Elimina versiones antiguas

3. **Espera** (5 minutos)

4. **Repite** indefinidamente

---

## ğŸ—ï¸ Arquitectura y Flujo

### Diagrama de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MAIN.PY                                â”‚
â”‚              (Sistema ETL + Limpieza)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚
    â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pipeline  â”‚   â”‚  DataCleaner â”‚
â”‚   (Extrae)  â”‚   â”‚  (Limpia)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
             â”‚               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
    â”‚  PostgreSQL     â”‚     â”‚
    â”‚  (Origen)       â”‚     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                       â”‚                       â”‚
    â–¼                       â”‚                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MinIO Bronce â”‚           â”‚               â”‚ MinIO Silver â”‚
â”‚ (CSV crudos) â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚ (CSV limpio) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directorio del Proyecto

```
Estacion_Meteorologica/
â”œâ”€â”€ main.py                          # ğŸš€ Punto de entrada (orquesta todo)
â”œâ”€â”€ run_scheduler.ps1                # Script PowerShell
â”œâ”€â”€ run_scheduler.sh                 # Script Bash
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ database_config.py           # Config PostgreSQL
â”‚   â””â”€â”€ minio_config.py              # Config MinIO
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ pipeline.py                  # OrquestaciÃ³n extracciÃ³n
â”‚   â”œâ”€â”€ table_processor.py           # Procesamiento por tabla
â”‚   â”œâ”€â”€ cleaners/                    # ğŸ†• MÃ“DULO DE LIMPIEZA
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_cleaner.py          # ğŸ†• Limpieza automÃ¡tica
â”‚   â”œâ”€â”€ extractors/
â”‚   â”‚   â”œâ”€â”€ data_extractor.py        # ExtracciÃ³n incremental
â”‚   â”‚   â””â”€â”€ table_inspector.py       # InspecciÃ³n de schema
â”‚   â”œâ”€â”€ writers/
â”‚   â”‚   â”œâ”€â”€ csv_writer.py            # Escritura CSV
â”‚   â”‚   â””â”€â”€ file_writer.py           # Interfaz base
â”‚   â”œâ”€â”€ uploaders/
â”‚   â”‚   â””â”€â”€ minio_uploader.py        # Carga a MinIO
â”‚   â”œâ”€â”€ control/
â”‚   â”‚   â””â”€â”€ control_manager.py       # GestiÃ³n de estado
â”‚   â”œâ”€â”€ etl_state.py                 # Estado JSON
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ db_utils.py              # Utilidades BD
â”‚
â”œâ”€â”€ .etl_state.json                  # Estado incremental
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ limpieza_template.ipynb   # Notebook alternativa
â”‚
â””â”€â”€ venv_meteo/                      # Entorno virtual
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos

- Python 3.8+
- PostgreSQL
- MinIO (servidor local o remoto)
- Windows: PowerShell 5+, Linux/Mac: Bash

### Paso 1: Crear Entorno Virtual

```powershell
# Windows
python -m venv venv_meteo
.\venv_meteo\Scripts\Activate

# Linux/Mac
python3 -m venv venv_meteo
source venv_meteo/bin/activate
```

### Paso 2: Instalar Dependencias

```bash
pip install pandas sqlalchemy psycopg2-binary minio
```

### Paso 3: Configurar Variables de Entorno

**En `run_scheduler.ps1` (Windows):**
```powershell
$env:PG_DB = "postgres"
$env:PG_USER = "postgres"
$env:PG_PASS = "1234"
$env:PG_HOST = "10.202.50.50"

$env:MINIO_ENDPOINT = "localhost:9000"
$env:MINIO_ACCESS_KEY = "minioadmin"
$env:MINIO_SECRET_KEY = "minioadmin"
$env:MINIO_BUCKET = "meteo-bronze"
```

**En `run_scheduler.sh` (Linux/Mac):**
```bash
export PG_HOST="10.202.50.50"
export PG_USER="postgres"
export PG_PASS="1234"
export PG_DB="postgres"
export MINIO_ENDPOINT="localhost:9000"
export MINIO_ACCESS_KEY="minioadmin"
export MINIO_SECRET_KEY="minioadmin"
export MINIO_BUCKET="meteo-bronze"
```

### Paso 4: Crear Buckets en MinIO

```bash
# Configurar alias MinIO
mc alias set myminio http://localhost:9000 minioadmin minioadmin

# Crear buckets
mc mb myminio/meteo-bronze
mc mb myminio/meteo-silver

# Verificar
mc ls myminio
```

---

## â–¶ï¸ Uso y EjecuciÃ³n

### EjecuciÃ³n Principal (RECOMENDADO)

```powershell
# Activar entorno
.\venv_meteo\Scripts\Activate

# Ejecutar
python main.py

# Salida esperada:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ Iniciando Sistema ETL Incremental PostgreSQL â†’ MinIO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 
# --- CICLO 1: 2025-12-03 09:40:12 ---
# Procesando tabla: sensor_readings
#    ğŸ“Š Incremental (timestamp)
# [INFO] Iniciando limpieza automÃ¡tica...
# ================================================================================
# [PROCESO] Limpiando sensor_readings
# ...
```

**Presionar Ctrl+C para detener.**

### Salida Esperada

```
--- CICLO 1: 2025-12-03 09:40:12 ---

Procesando tabla: sensor_readings
   ğŸ“Š Incremental (timestamp)
      > 2025-10-23T12:11:04.612475+00:00
   ğŸ“¦ Registros nuevos: 97
   âœ… Subido a MinIO: sensor_readings_bronce_20251203093625.csv

ğŸ¯ RESUMEN: 97 registros nuevos en este batch.

[INFO] Iniciando limpieza automÃ¡tica...

================================================================================
[PROCESO] Limpiando sensor_readings
================================================================================
[INFO] Encontrados 1 archivo(s) de sensor_readings
       - sensor_readings/sensor_readings_bronce_20251203093625.csv
[INFO] Combinando 1 archivo(s)...
[OK] Cargado: sensor_readings_bronce_20251203093625.csv (97 filas)
[OK] DataFrames combinados: 97 filas totales
[INFO] Limpiando datos...
[OK] Duplicados eliminados: 97 â†’ 97
[OK] Outliers en temperature: 13 reemplazados con mediana (24.00)
[OK] Columnas innecesarias eliminadas
[OK] Valores invÃ¡lidos filtrados: 0 eliminadas â†’ 97 filas finales
[INFO] Guardando en Silver (estrategia REPLACE)...
[EXITO] sensor_readings: 97 filas guardadas en Silver
[INFO] Archivo: sensor_readings_silver_20251203094013.csv
[INFO] Eliminando versiones antiguas...
[OK] Eliminado: sensor_readings_silver_20251203093847.csv
[OK] sensor_readings: 1 archivos eliminados (mantiene: sensor_readings_silver_20251203094013.csv)

[INFO] Esperando 300s...
```

---

## ğŸ”§ Estructura del CÃ³digo

### ConfiguraciÃ³n

#### **DatabaseConfig**
```python
from config import DatabaseConfig

config = DatabaseConfig()
# Propiedades:
# - user: str (usuario PostgreSQL)
# - password: str (contraseÃ±a)
# - host: str (IP/dominio)
# - database: str (nombre BD)
# - connection_url: str (URL formateada)
```

#### **MinIOConfig**
```python
from config import MinIOConfig

config = MinIOConfig()
# Propiedades:
# - endpoint: str (IP:puerto)
# - access_key: str
# - secret_key: str
# - bucket: str (meteo-bronze)
```

### Pipeline Principal

#### **ETLPipeline** (etl/pipeline.py)
Coordina extracciÃ³n de todas las tablas.

```python
pipeline = ETLPipeline(db_config, minio_config)
total_records = pipeline.process_batch()  # Una ronda
pipeline.run_continuous(interval_seconds=300)  # Bucle infinito
```

#### **TableProcessor** (etl/table_processor.py)
Procesa una tabla individual.

```python
processor = TableProcessor(connection, table_name, state_manager, ...)
records = processor.process()
```

**Flujo:**
1. Detecta columna de rastreo
2. Obtiene Ãºltimo valor procesado
3. Extrae datos nuevos
4. Guarda en Bronce
5. Actualiza estado

### ExtracciÃ³n

#### **DataExtractor** (etl/extractors/data_extractor.py)
Extrae datos incrementales.

```python
extractor = DataExtractor(connection, "sensor_readings", "timestamp", "timestamp")
df = extractor.extract_incremental(last_value="2025-10-23T12:11:04.612475+00:00")
```

#### **TableInspector** (etl/extractors/table_inspector.py)
Inspecciona estructura de tabla.

```python
inspector = TableInspector(connection)
tables = inspector.get_all_tables()
tracking_col, tracking_type = inspector.detect_tracking_column("sensor_readings")
```

### Limpieza AutomÃ¡tica ğŸ†•

#### **DataCleaner** (etl/cleaners/data_cleaner.py)
Limpia datos de Bronce y genera Silver.

```python
cleaner = DataCleaner(minio_config)
rows_saved = cleaner.clean_table("sensor_readings")
```

**Proceso automÃ¡tico:**
1. Lista archivos CSV en Bronce
2. Descarga y combina todos
3. Aplica limpieza
4. Guarda en Silver
5. Elimina versiones antiguas (REPLACE)

---

## ğŸ’¾ Capa Bronce

### Contenido
- Archivos CSV sin procesar
- Datos tal como salen de PostgreSQL
- Uno por cada extracciÃ³n incremental
- Formato: `tabla_bronce_YYYYMMDDHHMMSS.csv`

### Estructura en MinIO

```
meteo-bronze/
â”œâ”€â”€ sensor_readings/
â”‚   â”œâ”€â”€ sensor_readings_bronce_20251203093625.csv  (97 filas)
â”‚   â””â”€â”€ sensor_readings_bronce_20251203100123.csv  (45 filas)
â”œâ”€â”€ estaciones/
â”‚   â””â”€â”€ estaciones_bronce_20251203093625.csv  (50 filas)
â””â”€â”€ [otras tablas]/
```

### CaracterÃ­sticas
- âŒ Sin deduplicaciÃ³n
- âŒ Con outliers
- âŒ Columnas redundantes
- âœ… HistÃ³rico completo disponible

---

## ğŸ§¹ Capa Silver

### Contenido
- Archivos CSV limpios y consolidados
- **Un Ãºnico archivo por tabla** (estrategia REPLACE)
- Datos combinados de todas las extracciones
- Formato: `tabla_silver_YYYYMMDDHHMMSS.csv`

### Estructura en MinIO

```
meteo-silver/
â”œâ”€â”€ sensor_readings/
â”‚   â””â”€â”€ sensor_readings_silver_20251203094013.csv  (97 filas limpias)
â”œâ”€â”€ estaciones/
â”‚   â””â”€â”€ estaciones_silver_20251203094013.csv  (50 filas limpias)
â””â”€â”€ [otras tablas]/
```

### CaracterÃ­sticas
- âœ… Sin duplicados
- âœ… Outliers reemplazados con mediana
- âœ… Columnas innecesarias eliminadas
- âœ… Valores en rangos vÃ¡lidos
- âœ… **Un Ãºnico archivo consolidado**

---

## ğŸ§¹ Limpieza AutomÃ¡tica

### Operaciones de Limpieza

#### 1. EliminaciÃ³n de Duplicados
```
Antes:  100 filas
DespuÃ©s: 100 filas (ejemplo sin duplicados)
```

#### 2. Reemplazo de Outliers (MÃ©todo IQR)
```
Temperatura normal: 10Â°C - 50Â°C
CÃ¡lculo:
  Q1 = Percentil 25
  Q3 = Percentil 75
  IQR = Q3 - Q1
  LÃ­mite inferior = Q1 - 1.5 Ã— IQR
  LÃ­mite superior = Q3 + 1.5 Ã— IQR
  
Outliers detectados: 13
AcciÃ³n: Reemplazar con mediana (24.00Â°C)
```

#### 3. EliminaciÃ³n de Columnas
```
Columnas eliminadas:
- uv_level
- vibration
- rain_raw
- wind_raw
- pressure
```

#### 4. Filtrado de Rangos
```
Temperatura: 10Â°C - 50Â°C
Humedad: 0% - 100%
```

### Estrategia REPLACE

**Problema:** Â¿QuÃ© pasa si se ejecuta mÃºltiples veces?

**SoluciÃ³n:** REPLACE automÃ¡tico

```
CICLO 1 (09:00): Extrae 100 registros
  â†’ Bronce: archivo #1 (100 filas)
  â†’ Silver: sensor_readings_silver_20251203_090000.csv (100 limpias)

CICLO 2 (09:05): Extrae 50 nuevos registros
  â†’ Bronce: archivo #2 (50 filas)
  â†’ Combina Bronce #1 + #2 = 150 filas
  â†’ Silver: sensor_readings_silver_20251203_090500.csv (150 limpias)
  â†’ âŒ Elimina versiÃ³n anterior
  â†’ âœ… Mantiene solo la mÃ¡s reciente

CICLO 3 (09:10): Extrae 30 nuevos registros
  â†’ Bronce: archivo #3 (30 filas)
  â†’ Combina Bronce #1 + #2 + #3 = 180 filas
  â†’ Silver: sensor_readings_silver_20251203_091000.csv (180 limpias)
  â†’ âŒ Elimina versiÃ³n anterior
  â†’ âœ… Mantiene solo la mÃ¡s reciente
```

**Ventajas:**
- âœ… Dataset actualizado constantemente
- âœ… Archivo no crece indefinidamente
- âœ… Espacio controlado en MinIO
- âœ… Totalmente automÃ¡tico
- âœ… Sin intervenciÃ³n manual

---

## ğŸ” VerificaciÃ³n de Datos

### Ver archivos en MinIO
```bash
mc ls myminio/meteo-bronze/sensor_readings/
mc ls myminio/meteo-silver/sensor_readings/
```

### Descargar archivo
```bash
mc cp myminio/meteo-silver/sensor_readings/sensor_readings_silver*.csv ./
```

### Leer con Pandas
```python
import pandas as pd

df = pd.read_csv('sensor_readings_silver_20251203_094013.csv')
print(f"Filas: {len(df)}")
print(f"Columnas: {len(df.columns)}")
print(df.head())
```

### Ver estado de extracciones
```python
from etl.etl_state import StateManager

manager = StateManager()
manager.display_state()
```

---

## ğŸ› ï¸ SoluciÃ³n de Problemas

### Error: "No connection to PostgreSQL"
```powershell
# Verificar credenciales
$env:PG_HOST = "10.202.50.50"
$env:PG_USER = "postgres"
$env:PG_PASS = "1234"

# Probar conexiÃ³n
psql -h 10.202.50.50 -U postgres -d postgres -c "SELECT 1"
```

### Error: "MinIO connection refused"
```bash
# Verificar que MinIO estÃ¡ ejecutÃ¡ndose
curl http://localhost:9000

# Configurar alias
mc alias set myminio http://localhost:9000 minioadmin minioadmin
mc ls myminio
```

### Error: "Columna de rastreo no detectada"
Editar en `etl/extractors/table_inspector.py`:
```python
TIMESTAMP_COLUMNS = ['created_at', 'updated_at', 'timestamp', 'fecha', 'tu_columna']
```

### No se generan archivos en Silver
1. Verificar que hay datos en Bronce
2. Revisar logs de `DataCleaner`
3. Ejecutar manualmente: `cleaner.clean_table("sensor_readings")`

### Archivos viejos se acumulan en Silver
- Verificar que `_manage_versions()` se ejecuta
- Ver logs de "Eliminado:"
- El REPLACE debe ocurrir automÃ¡ticamente

---

## ğŸ“Š EstadÃ­sticas de Ejemplo

```
Sistema Ejecutado: 3 ciclos
PerÃ­odo: 09:00 - 09:10 (10 minutos)

BRONCE:
  sensor_readings: 3 archivos, 175 filas totales
  estaciones: 1 archivo, 50 filas
  
SILVER:
  sensor_readings: 1 archivo (REPLACE activo), 175 limpias
  estaciones: 1 archivo (REPLACE activo), 50 limpias

Limpieza:
  Duplicados eliminados: 0
  Outliers corregidos: 28
  Columnas eliminadas: 5
  RetenciÃ³n: 99.3%
```

---

## ğŸ“– DocumentaciÃ³n Adicional

- **MIGRACION_STATE_MANAGEMENT.md**: GestiÃ³n de estado JSON
- **ANALISIS_LIMPIEZA_CODIGO.md**: CÃ³digo eliminado durante refactorizaciÃ³n
- **ESTADO_FINAL_LIMPIEZA.md**: Estado actual del proyecto

---

**Ãšltima actualizaciÃ³n:** 3 de Diciembre de 2025  
**VersiÃ³n:** 3.0 (Con Limpieza AutomÃ¡tica)  
**Estado:** âœ… ProducciÃ³n


---

## ğŸ“‹ DescripciÃ³n General

Este proyecto implementa un **pipeline ETL modular orientado a objetos** que:

âœ… Extrae **solo registros nuevos** de todas las tablas de PostgreSQL  
âœ… Detecta automÃ¡ticamente **Primary Keys** o columnas de rastreo  
âœ… **Valida datos nuevos** antes de procesar  
âœ… Guarda datos en formato **CSV** (Bronce) y **Parquet** (Silver)  
âœ… Sube archivos a **MinIO** (almacenamiento objeto compatible S3)  
âœ… Mantiene un **control de estado** para evitar duplicados  
âœ… Ejecuta automÃ¡ticamente cada 5 minutos (configurable)  
âœ… **CÃ³digo modular**: cada componente en su propio archivo  
âœ… **FÃ¡cil mantenimiento**: estructura clara con type hints  

---

## ğŸ—ï¸ Arquitectura

### Sistema de Capas

```
PostgreSQL (Origen)
    â†“
[ETLPipeline] â†’ ExtracciÃ³n incremental
    â†“
Archivos CSV (/tmp)
    â†“
MinIO Capa BRONCE (Raw Data)
    â†“
[Limpieza & TransformaciÃ³n]
    â†“
MinIO Capa SILVER (Datos Limpios)
```

### Componentes del Sistema

```
pruebaMeteorologica/
â”œâ”€â”€ main.py                          # ğŸš€ Punto de entrada principal
â”œâ”€â”€ run_scheduler.ps1                # Script PowerShell (Windows)
â”œâ”€â”€ run_scheduler.sh                 # Script Bash (Linux)
â”œâ”€â”€ DOCUMENTACION.md                 # ğŸ“– DocumentaciÃ³n completa
â”‚
â”œâ”€â”€ config/                          # ğŸ“ Configuraciones
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database_config.py          # ConfiguraciÃ³n PostgreSQL
â”‚   â””â”€â”€ minio_config.py             # ConfiguraciÃ³n MinIO
â”‚
â”œâ”€â”€ etl/                             # ğŸ”§ Componentes del pipeline
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ db_utils.py                 # Utilidades BD centralizadas (NEW)
â”‚   â”œâ”€â”€ control_manager.py          # GestiÃ³n de tabla de control
â”‚   â”œâ”€â”€ table_inspector.py          # InspecciÃ³n de estructura de tablas
â”‚   â”œâ”€â”€ data_extractor.py           # ExtracciÃ³n incremental
â”‚   â”œâ”€â”€ parquet_writer.py           # Escritura de archivos Parquet
â”‚   â”œâ”€â”€ minio_uploader.py           # Subida a MinIO
â”‚   â”œâ”€â”€ table_processor.py          # Procesamiento de tabla individual
â”‚   â”œâ”€â”€ limpieza_bronce.py          # Limpieza automÃ¡tica
â”‚   â”œâ”€â”€ silver_layer.py             # TransformaciÃ³n Silver
â”‚   â””â”€â”€ pipeline.py                 # Pipeline completo
â”‚
â”œâ”€â”€ notebooks/                       # ğŸ“Š Notebooks Jupyter
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ limpieza_template.ipynb  # Limpieza manual (alternativa)
â”‚
â””â”€â”€ venv_meteo/                      # Entorno virtual Python
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Requisitos Previos

- **Python 3.8+**
- **PostgreSQL** corriendo con tablas a procesar
- **MinIO** instalado y configurado (servidor + cliente `mc`)
- **PySpark** (opcional, para silver_layer)

### 2. Instalar Dependencias

```powershell
# Entorno virtual
python -m venv venv_meteo
.\venv_meteo\Scripts\Activate

# Dependencias
pip install pandas sqlalchemy psycopg2-binary pyarrow minio
```

### 3. Configurar Variables de Entorno

**Archivo: `run_scheduler.ps1` (Windows)**
```powershell
# PostgreSQL
$env:PG_HOST = "10.202.50.50"       # IP o localhost
$env:PG_USER = "postgres"           # Usuario
$env:PG_PASS = "1234"               # ContraseÃ±a
$env:PG_DB = "postgres"             # Base de datos

# MinIO
$env:MINIO_ENDPOINT = "localhost:9000"      # IP:puerto
$env:MINIO_ACCESS_KEY = "minioadmin"        # Acceso
$env:MINIO_SECRET_KEY = "minioadmin"        # Secreto
$env:MINIO_BUCKET = "meteo-bronze"         # Bucket
```

**Archivo: `run_scheduler.sh` (Linux)**
```bash
export PG_HOST="10.202.50.50"
export PG_USER="postgres"
export PG_PASS="1234"
export PG_DB="postgres"

export MINIO_ENDPOINT="localhost:9000"
export MINIO_ACCESS_KEY="minioadmin"
export MINIO_SECRET_KEY="minioadmin"
export MINIO_BUCKET="meteo-bronze"
```

### 4. Configurar MinIO

```bash
# Configurar alias
mc alias set myminio http://localhost:9000 minioadmin minioadmin

# Crear buckets
mc mb myminio/meteo-bronze
mc mb myminio/meteo-silver

# Verificar
mc ls myminio
```

---

## â–¶ï¸ Uso

### OpciÃ³n 1: EjecuciÃ³n Manual Completa (RECOMENDADO)

```powershell
# Terminal PowerShell
cd c:\Users\Alumno_AI\Desktop\Estacion_Meteorologica

# Configurar variables
$env:PG_DB='postgres'
$env:PG_USER='postgres'
$env:PG_PASS='1234'
$env:PG_HOST='10.202.50.50'
$env:MINIO_ENDPOINT='localhost:9000'
$env:MINIO_ACCESS_KEY='minioadmin'
$env:MINIO_SECRET_KEY='minioadmin'
$env:MINIO_BUCKET='meteo-bronze'

# Ejecutar (ciclo continuo: extrae + limpia)
.\venv_meteo\Scripts\python.exe main.py

# Presionar Ctrl+C para detener
```

**Ciclo cada 5 minutos:**
```
1. Extrae datos de PostgreSQL â†’ Bronce (CSV)
2. Limpia automÃ¡ticamente â†’ Silver (Parquet)
3. Espera 5 minutos
4. Repite
```

### OpciÃ³n 2: Limpieza Manual

```powershell
# Solo limpiar datos existentes en Bronce
.\venv_meteo\Scripts\python.exe limpiar_bronce.py
```

### OpciÃ³n 3: Notebook Interactivo

```
1. Abrir: notebooks/templates/limpieza_template.ipynb
2. Ejecutar celdas 1-19 (configuraciÃ³n)
3. Ejecutar celda 20 (limpieza)
4. Datos guardados en Silver
```

---

## ğŸ”§ Estructura del CÃ³digo

### Configuraciones (`config/`)

#### **DatabaseConfig** (database_config.py)
```python
# Encapsula configuraciÃ³n de PostgreSQL
config = DatabaseConfig()
connection_url = config.connection_url  # postgresql://...
```

**Propiedades:**
- `user`: Usuario PostgreSQL
- `password`: ContraseÃ±a
- `host`: IP servidor
- `database`: Base de datos
- `connection_url`: URL formateada

#### **MinIOConfig** (minio_config.py)
```python
# Encapsula configuraciÃ³n de MinIO
config = MinIOConfig()
bucket = config.bucket  # meteo-bronze
silver_bucket = config.silver_bucket  # meteo-silver
```

---

### Pipeline ETL (`etl/`)

#### **1. ETLControlManager** (control_manager.py)
Rastrea el estado de extracciÃ³n de cada tabla.

```python
manager = ETLControlManager(connection)
last_value = manager.get_last_extracted_value("sensor_readings")
manager.update_last_extracted_value("sensor_readings", 100, "id")
```

**Tabla de control:**
```sql
CREATE TABLE etl_control (
    table_name VARCHAR(255) PRIMARY KEY,
    last_extracted_value VARCHAR(255),
    last_extracted_at TIMESTAMP,
    tracking_column VARCHAR(255)
)
```

#### **2. TableInspector** (table_inspector.py)
Inspecciona estructura de tablas.

```python
inspector = TableInspector(connection)
tables = inspector.get_all_tables()
columns = inspector.get_columns("sensor_readings")
tracking_col = inspector.detect_tracking_column("sensor_readings")
```

**DetecciÃ³n de columna de rastreo (orden de prioridad):**
1. Timestamp: `created_at`, `updated_at`, `timestamp`
2. PRIMARY KEY numÃ©rico
3. Columna `id` genÃ©rica

#### **3. DataExtractor** (data_extractor.py)
Extrae datos incrementales.

```python
extractor = DataExtractor(connection, "sensor_readings")
df = extractor.extract_incremental(last_value=100)
```

**LÃ³gica:**
- Si `last_value` existe: `SELECT * WHERE columna > last_value`
- Si primera carga: `SELECT * FROM tabla`

#### **4. ParquetWriter** (parquet_writer.py)
Escriba archivos Parquet.

```python
writer = ParquetWriter()
writer.write(df, "output.parquet")
```

**Estrategia Pattern:** FÃ¡cil agregar CSVWriter, JSONWriter, etc.

#### **5. MinIOUploader** (minio_uploader.py)
Sube archivos a MinIO.

```python
uploader = MinIOUploader(config)
uploader.upload("local_file.parquet", "sensor_readings", "file_name.parquet")
```

#### **6. TableProcessor** (table_processor.py)
Orquesta procesamiento completo de una tabla.

```python
processor = TableProcessor(connection, config)
records_count = processor.process("sensor_readings")  # Retorna cantidad
```

**Flujo:**
1. Detecta columna rastreo
2. Obtiene Ãºltimo valor procesado
3. Extrae datos nuevos
4. Guarda en Parquet
5. Sube a MinIO
6. Actualiza control

#### **7. ETLPipeline** (pipeline.py)
Pipeline principal que coordina todo.

```python
pipeline = ETLPipeline(config)
pipeline.process_batch()  # Procesa una ronda
pipeline.run_continuous(interval_seconds=300)  # Bucle infinito (5 min)
```

#### **8. Limpieza (limpieza_bronce.py)**
Limpieza de datos automÃ¡tica.

```python
cleaner = LimpiezaBronce(config)
cleaner.procesar_tabla("sensor_readings")
```

**Operaciones:**
- Elimina duplicados
- Reemplaza outliers con mediana (IQR)
- Elimina columnas innecesarias
- Filtra valores invÃ¡lidos

#### **9. SilverLayer** (silver_layer.py)
TransformaciÃ³n de Bronce a Silver.

```python
silver = SilverLayer(config)
exito = silver.process("sensor_readings")  # Booleano
```

**PatrÃ³n Strategy para limpieza:**
- `DataCleaner` (clase abstracta)
- `SensorReadingsCleaner` (implementaciÃ³n especÃ­fica)
- FÃ¡cil extender con nuevas limpiadoras

#### **10. DatabaseUtils** (db_utils.py - NUEVO)
Centraliza operaciones de base de datos.

```python
# Queries reutilizables
result = DatabaseUtils.fetch_one(connection, query, params)
rows = DatabaseUtils.fetch_all(connection, query)
DatabaseUtils.execute(connection, query, params)
```

**Clases:**
- `DatabaseUtils`: MÃ©todos estÃ¡ticos para ejecutar queries
- `TableQueryBuilder`: Constructor de queries

---

## ğŸ¯ RefactorizaciÃ³n OOP

### CaracterÃ­sticas de DiseÃ±o

âœ… **SeparaciÃ³n de responsabilidades**: Cada clase, una funciÃ³n  
âœ… **Type hints**: 100% cobertura de tipos  
âœ… **Patrones de diseÃ±o**: Strategy, Factory, Builder  
âœ… **SOLID principles**: Todos implementados  
âœ… **AbstracciÃ³n**: Clases base (Config, DataCleaner)  
âœ… **Modularidad**: Componentes reutilizables  

### Clases Base (Herencia)

```python
# Base de configuraciones
class Config:
    @staticmethod
    def get_env(key: str, default: Optional[str] = None) -> str:
        value = os.environ.get(key, default)
        if value is None:
            raise ValueError(f"Variable requerida: {key}")
        return value

# DatabaseConfig hereda de Config
class DatabaseConfig(Config):
    def __init__(self, user: Optional[str] = None, ...):
        self.user = user or self.get_env('PG_USER', 'postgres')
```

### PatrÃ³n Strategy (Limpieza)

```python
from abc import ABC, abstractmethod

class DataCleaner(ABC):
    @abstractmethod
    def clean(self, df: DataFrame) -> DataFrame:
        pass

class SensorReadingsCleaner(DataCleaner):
    def clean(self, df: DataFrame) -> DataFrame:
        df = self._remove_duplicates(df)
        df = self._replace_outliers(df, "temperature")
        df = self._drop_unnecessary_columns(df)
        return df

# Usar
CLEANERS = {"sensor_readings": SensorReadingsCleaner()}
```

### Type Hints Completos

```python
def process(self, table_name: str) -> bool:
    """Procesa una tabla.
    
    Args:
        table_name: Nombre de la tabla
        
    Returns:
        bool: True si Ã©xito, False si error
    """
    pass
```

---

## ğŸ“Š Procesamiento de Datos

### Capa Bronce (Bronze)
- **Tipo**: CSV
- **Contenido**: Datos sin procesar
- **CaracterÃ­sticas**:
  - Contiene duplicados
  - Contiene outliers
  - Columnas redundantes

### Capa Silver (Silver)
- **Tipo**: CSV
- **Contenido**: Datos procesados
- **CaracterÃ­sticas**:
  - Sin duplicados
  - Outliers reemplazados con mediana
  - Solo columnas relevantes
- **Estrategia**: **REPLACE** - Solo mantiene el dataset mÃ¡s reciente

### Operaciones de Limpieza (sensor_readings)

1. **Eliminar duplicados**
   ```python
   df = df.distinct()  # Spark: elimina filas idÃ©nticas
   ```

2. **Reemplazar outliers** (IQR method)
   ```
   Q1 = percentil 25
   Q3 = percentil 75
   IQR = Q3 - Q1
   Limites = [Q1 - 1.5*IQR, Q3 + 1.5*IQR]
   Outliers: reemplazar con mediana
   ```

3. **Eliminar columnas**
   ```
   uv_level, vibration, rain_raw, wind_raw, pressure
   ```

4. **Filtrar valores invÃ¡lidos**
   ```
   temperature: 10Â°C - 50Â°C
   humidity: 0% - 100%
   ```

### ğŸ”„ Estrategia REPLACE: GestiÃ³n de Versiones

**Problema:** Si extraes mÃºltiples veces, Â¿cÃ³mo evitar acumular archivos?

**SoluciÃ³n:** Estrategia REPLACE automÃ¡tica

```
CICLO 1 (09:00):
  âœ… Extrae 100 filas â†’ Bronce CSV #1
  âœ… Limpia â†’ Silver: sensor_readings_silver_20251202_090000.csv (100 filas)

CICLO 2 (09:05):
  âœ… Extrae 50 filas â†’ Bronce CSV #2
  âœ… Combina CSV #1 + #2 = 150 filas (sin duplicados)
  âœ… Limpia â†’ Silver: sensor_readings_silver_20251202_090500.csv (150 filas)
  âœ… Elimina automÃ¡ticamente versiÃ³n anterior

CICLO 3 (09:10):
  âœ… Extrae 30 filas â†’ Bronce CSV #3
  âœ… Combina todos = 180 filas (sin duplicados)
  âœ… Limpia â†’ Silver: sensor_readings_silver_20251202_091000.csv (180 filas)
  âœ… Elimina automÃ¡ticamente versiÃ³n anterior
```

**Ventajas:**
- âœ… Siempre tienes el dataset mÃ¡s reciente
- âœ… El archivo NO crece indefinidamente
- âœ… Espacio en MinIO controlado y predecible
- âœ… Proceso automÃ¡tico, sin intervenciÃ³n manual

**CÃ³mo funciona:**
1. Se guarda nuevo CSV en Silver con timestamp
2. El mÃ³dulo `SilverManager` detecta versiones antiguas
3. AutomÃ¡ticamente elimina todas EXCEPTO la mÃ¡s reciente
4. Solo un archivo activo por tabla en Silver

---

## ğŸ“‚ Estructura de Archivos en MinIO

### Bronce (meteo-bronze)
```
meteo-bronze/
â”œâ”€â”€ sensor_readings/
â”‚   â”œâ”€â”€ sensor_readings_bronce_20251202_091647.csv  (97 filas)
â”‚   â””â”€â”€ sensor_readings_bronce_20251202_101823.csv  (30 filas)
â”œâ”€â”€ weather/
â”‚   â””â”€â”€ weather_bronce_20251202_091647.csv  (50 filas)
â””â”€â”€ [otras tablas]/
    â””â”€â”€ ...
```

### Silver (meteo-silver)
```
meteo-silver/
â”œâ”€â”€ sensor_readings/
â”‚   â”œâ”€â”€ sensor_readings_silver_20251202_130210.csv  (127 filas limpias)
â”‚   â””â”€â”€ sensor_readings_silver_20251202_140521.csv  (55 filas limpias)
â”œâ”€â”€ weather/
â”‚   â””â”€â”€ weather_silver_20251202_130210.csv  (48 filas limpias)
â””â”€â”€ [otras tablas]/
    â””â”€â”€ ...
```

---

## ğŸ” VerificaciÃ³n de Datos

### Ver archivos en MinIO
```bash
mc ls myminio/meteo-bronze/
mc ls myminio/meteo-bronze/sensor_readings/
```

### Descargar archivo
```bash
mc cp myminio/meteo-bronze/sensor_readings/sensor_readings_bronce_*.csv ./
```

### Leer con Python
```python
import pandas as pd

df = pd.read_csv('sensor_readings_bronce_20251202_091647.csv')
print(f"Filas: {len(df)}")
print(df.head())
```

### Consultar tabla de control
```sql
SELECT * FROM etl_control;
```

**Resultado esperado:**
```
table_name     | last_extracted_value | last_extracted_at  | tracking_column
---------------|----------------------|--------------------|-----------------
sensor_readings| 1000                 | 2025-12-02 13:02   | id
weather        | 500                  | 2025-12-02 13:01   | measurement_id
```

---

## ğŸ› ï¸ SoluciÃ³n de Problemas

### Error: "El cliente 'mc' no estÃ¡ instalado"
```bash
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc
sudo mv mc /usr/local/bin/
```

### Error: "Connection refused" en PostgreSQL
```powershell
# Verificar credenciales
psql -h 10.202.50.50 -U postgres -d postgres

# Verificar variables de entorno
echo $env:PG_HOST
echo $env:PG_USER
```

### Error: "FallÃ³ la carga a MinIO"
```bash
# Verificar alias
mc alias list
mc alias set myminio http://localhost:9000 minioadmin minioadmin

# Verificar conectividad
mc ls myminio
```

### Error: "Table etl_control not found"
El sistema crea la tabla automÃ¡ticamente en la primera ejecuciÃ³n. Si no se crea:
```sql
CREATE TABLE etl_control (
    table_name VARCHAR(255) PRIMARY KEY,
    last_extracted_value VARCHAR(255),
    last_extracted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    tracking_column VARCHAR(255)
)
```

### No detecta columna de rastreo
Editar en `etl/table_inspector.py`:
```python
# Agregar candidatos personalizados
timestamp_candidates = ['created_at', 'updated_at', 'fecha', 'date', 'tu_columna']
```

---

## ğŸ“ˆ Ejemplo de EjecuciÃ³n Completa

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ Iniciando Sistema ETL Incremental
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š Base de datos: postgres@10.202.50.50
ğŸ—„ï¸  MinIO Bucket: meteo-bronze
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

--- INICIO DE BATCH: 2025-12-02 09:16:47 ---

Procesando tabla: sensor_readings
   ğŸ“Š Detectada columna: id (numÃ©rica)
   ğŸ” Ãšltimo valor: 900
   ğŸ“¦ Registros nuevos: 97
   ğŸ’¾ Guardando: sensor_readings_bronce_20251202_091647.csv
   âœ… Subido a Bronce
   ğŸ§¹ Limpiando...
   âœ… Duplicados eliminados: 97 â†’ 97
   âœ… Outliers reemplazados: 2
   âœ… Columnas eliminadas: 5
   âœ… Subido a Silver: sensor_readings_silver_20251202_091647.csv

Procesando tabla: weather
   ğŸ“Š Detectada columna: created_at (timestamp)
   ğŸ” Ãšltimo valor: 2025-12-02 08:00:00
   ğŸ“¦ Registros nuevos: 50
   ğŸ’¾ Guardando: weather_bronce_20251202_091647.csv
   âœ… Subido a Bronce
   ğŸ§¹ Limpiando...
   âœ… Duplicados eliminados: 50 â†’ 50
   âœ… Outliers reemplazados: 1
   âœ… Subido a Silver: weather_silver_20251202_091647.csv

ğŸ¯ RESUMEN: 147 registros nuevos en este batch.
â° PrÃ³xima ejecuciÃ³n: 09:21:47 (en 5 minutos)
```

---

## ğŸ“ PrÃ³ximos Pasos

- [ ] Agregar pruebas unitarias
- [ ] Implementar logging estructura (logging module)
- [ ] Agregar mÃ©tricas y monitoreo
- [ ] Crear CLI para administraciÃ³n
- [ ] Implementar re-intentos automÃ¡ticos
- [ ] Agregar alertas por errores

---

## ğŸ‘¤ InformaciÃ³n del Proyecto

- **Tipo**: Data Lake ETL
- **Arquitectura**: Modular, OOP, SOLID
- **Lenguaje**: Python 3.8+
- **Frameworks**: SQLAlchemy, Pandas, PySpark, MinIO
- **Bases de datos**: PostgreSQL, MinIO (Object Storage)

---

## ğŸ“– DocumentaciÃ³n TÃ©cnica

Este archivo consolida toda la documentaciÃ³n tÃ©cnica del proyecto. Todos los componentes estÃ¡n documentados con:
- Type hints completos
- Docstrings en mÃ©todos
- Ejemplos de uso
- Configuraciones recomendadas

Para preguntas especÃ­ficas sobre componentes individuales, consultar los archivos en `etl/` y `config/`.

---

**Ãšltima actualizaciÃ³n:** 2 de Diciembre de 2025  
**VersiÃ³n:** 2.0 (RefactorizaciÃ³n OOP Completa)
