# ğŸŒ¤ï¸ Sistema ETL Incremental PostgreSQL â†’ MinIO

Sistema automatizado de extracciÃ³n, transformaciÃ³n y carga (ETL) que extrae **solo datos nuevos** de PostgreSQL y los almacena en MinIO con arquitectura Data Lake de capas (Bronce â†’ Silver).

---

## ğŸ“‹ Contenido

1. [DescripciÃ³n General](#descripciÃ³n-general)
2. [Arquitectura](#arquitectura)
3. [InstalaciÃ³n y ConfiguraciÃ³n](#instalaciÃ³n-y-configuraciÃ³n)
4. [Uso](#uso)
5. [Estructura del CÃ³digo](#estructura-del-cÃ³digo)
6. [RefactorizaciÃ³n OOP](#refactorizaciÃ³n-oop)
7. [Procesamiento de Datos](#procesamiento-de-datos)
8. [SoluciÃ³n de Problemas](#soluciÃ³n-de-problemas)

---

## ğŸ“‹ DescripciÃ³n General

Este proyecto implementa un **pipeline ETL modular orientado a objetos** que:

âœ… Extrae **solo registros nuevos** de todas las tablas de PostgreSQL  
âœ… Detecta automÃ¡ticamente **Primary Keys** o columnas de rastreo  
âœ… **Valida datos nuevos** antes de procesar  
âœ… Guarda datos en formato **CSV** (Bronce) y **Parquet** (Silver)  
âœ… Sube archivos a **MinIO** (almacenamiento objeto compatible S3)  
âœ… Mantiene un **control de estado** para evitar duplicados  
âœ… Ejecuta automÃ¡ticamente cada 5 minutos (configurable)  
âœ… **CÃ³digo modular**: cada componente en su propio archivo  
âœ… **FÃ¡cil mantenimiento**: estructura clara con type hints  

---

## ğŸ—ï¸ Arquitectura

### Sistema de Capas

```
PostgreSQL (Origen)
    â†“
[ETLPipeline] â†’ ExtracciÃ³n incremental
    â†“
Archivos CSV (/tmp)
    â†“
MinIO Capa BRONCE (Raw Data)
    â†“
[Limpieza & TransformaciÃ³n]
    â†“
MinIO Capa SILVER (Datos Limpios)
```

### Componentes del Sistema

```
pruebaMeteorologica/
â”œâ”€â”€ main.py                          # ğŸš€ Punto de entrada principal
â”œâ”€â”€ run_scheduler.ps1                # Script PowerShell (Windows)
â”œâ”€â”€ run_scheduler.sh                 # Script Bash (Linux)
â”œâ”€â”€ DOCUMENTACION.md                 # ğŸ“– DocumentaciÃ³n completa
â”‚
â”œâ”€â”€ config/                          # ğŸ“ Configuraciones
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database_config.py          # ConfiguraciÃ³n PostgreSQL
â”‚   â””â”€â”€ minio_config.py             # ConfiguraciÃ³n MinIO
â”‚
â”œâ”€â”€ etl/                             # ğŸ”§ Componentes del pipeline
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ db_utils.py                 # Utilidades BD centralizadas (NEW)
â”‚   â”œâ”€â”€ control_manager.py          # GestiÃ³n de tabla de control
â”‚   â”œâ”€â”€ table_inspector.py          # InspecciÃ³n de estructura de tablas
â”‚   â”œâ”€â”€ data_extractor.py           # ExtracciÃ³n incremental
â”‚   â”œâ”€â”€ parquet_writer.py           # Escritura de archivos Parquet
â”‚   â”œâ”€â”€ minio_uploader.py           # Subida a MinIO
â”‚   â”œâ”€â”€ table_processor.py          # Procesamiento de tabla individual
â”‚   â”œâ”€â”€ limpieza_bronce.py          # Limpieza automÃ¡tica
â”‚   â”œâ”€â”€ silver_layer.py             # TransformaciÃ³n Silver
â”‚   â””â”€â”€ pipeline.py                 # Pipeline completo
â”‚
â”œâ”€â”€ notebooks/                       # ğŸ“Š Notebooks Jupyter
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ limpieza_template.ipynb  # Limpieza manual (alternativa)
â”‚
â””â”€â”€ venv_meteo/                      # Entorno virtual Python
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Requisitos Previos

- **Python 3.8+**
- **PostgreSQL** corriendo con tablas a procesar
- **MinIO** instalado y configurado (servidor + cliente `mc`)
- **PySpark** (opcional, para silver_layer)

### 2. Instalar Dependencias

```powershell
# Entorno virtual
python -m venv venv_meteo
.\venv_meteo\Scripts\Activate

# Dependencias
pip install pandas sqlalchemy psycopg2-binary pyarrow minio
```

### 3. Configurar Variables de Entorno

**Archivo: `run_scheduler.ps1` (Windows)**
```powershell
# PostgreSQL
$env:PG_HOST = "10.202.50.50"       # IP o localhost
$env:PG_USER = "postgres"           # Usuario
$env:PG_PASS = "1234"               # ContraseÃ±a
$env:PG_DB = "postgres"             # Base de datos

# MinIO
$env:MINIO_ENDPOINT = "localhost:9000"      # IP:puerto
$env:MINIO_ACCESS_KEY = "minioadmin"        # Acceso
$env:MINIO_SECRET_KEY = "minioadmin"        # Secreto
$env:MINIO_BUCKET = "meteo-bronze"         # Bucket
```

**Archivo: `run_scheduler.sh` (Linux)**
```bash
export PG_HOST="10.202.50.50"
export PG_USER="postgres"
export PG_PASS="1234"
export PG_DB="postgres"

export MINIO_ENDPOINT="localhost:9000"
export MINIO_ACCESS_KEY="minioadmin"
export MINIO_SECRET_KEY="minioadmin"
export MINIO_BUCKET="meteo-bronze"
```

### 4. Configurar MinIO

```bash
# Configurar alias
mc alias set myminio http://localhost:9000 minioadmin minioadmin

# Crear buckets
mc mb myminio/meteo-bronze
mc mb myminio/meteo-silver

# Verificar
mc ls myminio
```

---

## â–¶ï¸ Uso

### OpciÃ³n 1: EjecuciÃ³n Manual Completa (RECOMENDADO)

```powershell
# Terminal PowerShell
cd c:\Users\Alumno_AI\Desktop\Estacion_Meteorologica

# Configurar variables
$env:PG_DB='postgres'
$env:PG_USER='postgres'
$env:PG_PASS='1234'
$env:PG_HOST='10.202.50.50'
$env:MINIO_ENDPOINT='localhost:9000'
$env:MINIO_ACCESS_KEY='minioadmin'
$env:MINIO_SECRET_KEY='minioadmin'
$env:MINIO_BUCKET='meteo-bronze'

# Ejecutar (ciclo continuo: extrae + limpia)
.\venv_meteo\Scripts\python.exe main.py

# Presionar Ctrl+C para detener
```

**Ciclo cada 5 minutos:**
```
1. Extrae datos de PostgreSQL â†’ Bronce (CSV)
2. Limpia automÃ¡ticamente â†’ Silver (Parquet)
3. Espera 5 minutos
4. Repite
```

### OpciÃ³n 2: Limpieza Manual

```powershell
# Solo limpiar datos existentes en Bronce
.\venv_meteo\Scripts\python.exe limpiar_bronce.py
```

### OpciÃ³n 3: Notebook Interactivo

```
1. Abrir: notebooks/templates/limpieza_template.ipynb
2. Ejecutar celdas 1-19 (configuraciÃ³n)
3. Ejecutar celda 20 (limpieza)
4. Datos guardados en Silver
```

---

## ğŸ”§ Estructura del CÃ³digo

### Configuraciones (`config/`)

#### **DatabaseConfig** (database_config.py)
```python
# Encapsula configuraciÃ³n de PostgreSQL
config = DatabaseConfig()
connection_url = config.connection_url  # postgresql://...
```

**Propiedades:**
- `user`: Usuario PostgreSQL
- `password`: ContraseÃ±a
- `host`: IP servidor
- `database`: Base de datos
- `connection_url`: URL formateada

#### **MinIOConfig** (minio_config.py)
```python
# Encapsula configuraciÃ³n de MinIO
config = MinIOConfig()
bucket = config.bucket  # meteo-bronze
silver_bucket = config.silver_bucket  # meteo-silver
```

---

### Pipeline ETL (`etl/`)

#### **1. ETLControlManager** (control_manager.py)
Rastrea el estado de extracciÃ³n de cada tabla.

```python
manager = ETLControlManager(connection)
last_value = manager.get_last_extracted_value("sensor_readings")
manager.update_last_extracted_value("sensor_readings", 100, "id")
```

**Tabla de control:**
```sql
CREATE TABLE etl_control (
    table_name VARCHAR(255) PRIMARY KEY,
    last_extracted_value VARCHAR(255),
    last_extracted_at TIMESTAMP,
    tracking_column VARCHAR(255)
)
```

#### **2. TableInspector** (table_inspector.py)
Inspecciona estructura de tablas.

```python
inspector = TableInspector(connection)
tables = inspector.get_all_tables()
columns = inspector.get_columns("sensor_readings")
tracking_col = inspector.detect_tracking_column("sensor_readings")
```

**DetecciÃ³n de columna de rastreo (orden de prioridad):**
1. Timestamp: `created_at`, `updated_at`, `timestamp`
2. PRIMARY KEY numÃ©rico
3. Columna `id` genÃ©rica

#### **3. DataExtractor** (data_extractor.py)
Extrae datos incrementales.

```python
extractor = DataExtractor(connection, "sensor_readings")
df = extractor.extract_incremental(last_value=100)
```

**LÃ³gica:**
- Si `last_value` existe: `SELECT * WHERE columna > last_value`
- Si primera carga: `SELECT * FROM tabla`

#### **4. ParquetWriter** (parquet_writer.py)
Escriba archivos Parquet.

```python
writer = ParquetWriter()
writer.write(df, "output.parquet")
```

**Estrategia Pattern:** FÃ¡cil agregar CSVWriter, JSONWriter, etc.

#### **5. MinIOUploader** (minio_uploader.py)
Sube archivos a MinIO.

```python
uploader = MinIOUploader(config)
uploader.upload("local_file.parquet", "sensor_readings", "file_name.parquet")
```

#### **6. TableProcessor** (table_processor.py)
Orquesta procesamiento completo de una tabla.

```python
processor = TableProcessor(connection, config)
records_count = processor.process("sensor_readings")  # Retorna cantidad
```

**Flujo:**
1. Detecta columna rastreo
2. Obtiene Ãºltimo valor procesado
3. Extrae datos nuevos
4. Guarda en Parquet
5. Sube a MinIO
6. Actualiza control

#### **7. ETLPipeline** (pipeline.py)
Pipeline principal que coordina todo.

```python
pipeline = ETLPipeline(config)
pipeline.process_batch()  # Procesa una ronda
pipeline.run_continuous(interval_seconds=300)  # Bucle infinito (5 min)
```

#### **8. Limpieza (limpieza_bronce.py)**
Limpieza de datos automÃ¡tica.

```python
cleaner = LimpiezaBronce(config)
cleaner.procesar_tabla("sensor_readings")
```

**Operaciones:**
- Elimina duplicados
- Reemplaza outliers con mediana (IQR)
- Elimina columnas innecesarias
- Filtra valores invÃ¡lidos

#### **9. SilverLayer** (silver_layer.py)
TransformaciÃ³n de Bronce a Silver.

```python
silver = SilverLayer(config)
exito = silver.process("sensor_readings")  # Booleano
```

**PatrÃ³n Strategy para limpieza:**
- `DataCleaner` (clase abstracta)
- `SensorReadingsCleaner` (implementaciÃ³n especÃ­fica)
- FÃ¡cil extender con nuevas limpiadoras

#### **10. DatabaseUtils** (db_utils.py - NUEVO)
Centraliza operaciones de base de datos.

```python
# Queries reutilizables
result = DatabaseUtils.fetch_one(connection, query, params)
rows = DatabaseUtils.fetch_all(connection, query)
DatabaseUtils.execute(connection, query, params)
```

**Clases:**
- `DatabaseUtils`: MÃ©todos estÃ¡ticos para ejecutar queries
- `TableQueryBuilder`: Constructor de queries
- `ETLControlQueries`: Queries de tabla de control

---

## ğŸ¯ RefactorizaciÃ³n OOP

### CaracterÃ­sticas de DiseÃ±o

âœ… **SeparaciÃ³n de responsabilidades**: Cada clase, una funciÃ³n  
âœ… **Type hints**: 100% cobertura de tipos  
âœ… **Patrones de diseÃ±o**: Strategy, Factory, Builder  
âœ… **SOLID principles**: Todos implementados  
âœ… **AbstracciÃ³n**: Clases base (Config, DataCleaner)  
âœ… **Modularidad**: Componentes reutilizables  

### Clases Base (Herencia)

```python
# Base de configuraciones
class Config:
    @staticmethod
    def get_env(key: str, default: Optional[str] = None) -> str:
        value = os.environ.get(key, default)
        if value is None:
            raise ValueError(f"Variable requerida: {key}")
        return value

# DatabaseConfig hereda de Config
class DatabaseConfig(Config):
    def __init__(self, user: Optional[str] = None, ...):
        self.user = user or self.get_env('PG_USER', 'postgres')
```

### PatrÃ³n Strategy (Limpieza)

```python
from abc import ABC, abstractmethod

class DataCleaner(ABC):
    @abstractmethod
    def clean(self, df: DataFrame) -> DataFrame:
        pass

class SensorReadingsCleaner(DataCleaner):
    def clean(self, df: DataFrame) -> DataFrame:
        df = self._remove_duplicates(df)
        df = self._replace_outliers(df, "temperature")
        df = self._drop_unnecessary_columns(df)
        return df

# Usar
CLEANERS = {"sensor_readings": SensorReadingsCleaner()}
```

### Type Hints Completos

```python
def process(self, table_name: str) -> bool:
    """Procesa una tabla.
    
    Args:
        table_name: Nombre de la tabla
        
    Returns:
        bool: True si Ã©xito, False si error
    """
    pass
```

---

## ğŸ“Š Procesamiento de Datos

### Capa Bronce (Bronze)
- **Tipo**: CSV
- **Contenido**: Datos sin procesar
- **CaracterÃ­sticas**:
  - Contiene duplicados
  - Contiene outliers
  - Columnas redundantes

### Capa Silver (Silver)
- **Tipo**: CSV
- **Contenido**: Datos procesados
- **CaracterÃ­sticas**:
  - Sin duplicados
  - Outliers reemplazados con mediana
  - Solo columnas relevantes
- **Estrategia**: **REPLACE** - Solo mantiene el dataset mÃ¡s reciente

### Operaciones de Limpieza (sensor_readings)

1. **Eliminar duplicados**
   ```python
   df = df.distinct()  # Spark: elimina filas idÃ©nticas
   ```

2. **Reemplazar outliers** (IQR method)
   ```
   Q1 = percentil 25
   Q3 = percentil 75
   IQR = Q3 - Q1
   Limites = [Q1 - 1.5*IQR, Q3 + 1.5*IQR]
   Outliers: reemplazar con mediana
   ```

3. **Eliminar columnas**
   ```
   uv_level, vibration, rain_raw, wind_raw, pressure
   ```

4. **Filtrar valores invÃ¡lidos**
   ```
   temperature: 10Â°C - 50Â°C
   humidity: 0% - 100%
   ```

### ğŸ”„ Estrategia REPLACE: GestiÃ³n de Versiones

**Problema:** Si extraes mÃºltiples veces, Â¿cÃ³mo evitar acumular archivos?

**SoluciÃ³n:** Estrategia REPLACE automÃ¡tica

```
CICLO 1 (09:00):
  âœ… Extrae 100 filas â†’ Bronce CSV #1
  âœ… Limpia â†’ Silver: sensor_readings_silver_20251202_090000.csv (100 filas)

CICLO 2 (09:05):
  âœ… Extrae 50 filas â†’ Bronce CSV #2
  âœ… Combina CSV #1 + #2 = 150 filas (sin duplicados)
  âœ… Limpia â†’ Silver: sensor_readings_silver_20251202_090500.csv (150 filas)
  âœ… Elimina automÃ¡ticamente versiÃ³n anterior

CICLO 3 (09:10):
  âœ… Extrae 30 filas â†’ Bronce CSV #3
  âœ… Combina todos = 180 filas (sin duplicados)
  âœ… Limpia â†’ Silver: sensor_readings_silver_20251202_091000.csv (180 filas)
  âœ… Elimina automÃ¡ticamente versiÃ³n anterior
```

**Ventajas:**
- âœ… Siempre tienes el dataset mÃ¡s reciente
- âœ… El archivo NO crece indefinidamente
- âœ… Espacio en MinIO controlado y predecible
- âœ… Proceso automÃ¡tico, sin intervenciÃ³n manual

**CÃ³mo funciona:**
1. Se guarda nuevo CSV en Silver con timestamp
2. El mÃ³dulo `SilverManager` detecta versiones antiguas
3. AutomÃ¡ticamente elimina todas EXCEPTO la mÃ¡s reciente
4. Solo un archivo activo por tabla en Silver

---

## ğŸ“‚ Estructura de Archivos en MinIO

### Bronce (meteo-bronze)
```
meteo-bronze/
â”œâ”€â”€ sensor_readings/
â”‚   â”œâ”€â”€ sensor_readings_bronce_20251202_091647.csv  (97 filas)
â”‚   â””â”€â”€ sensor_readings_bronce_20251202_101823.csv  (30 filas)
â”œâ”€â”€ weather/
â”‚   â””â”€â”€ weather_bronce_20251202_091647.csv  (50 filas)
â””â”€â”€ [otras tablas]/
    â””â”€â”€ ...
```

### Silver (meteo-silver)
```
meteo-silver/
â”œâ”€â”€ sensor_readings/
â”‚   â”œâ”€â”€ sensor_readings_silver_20251202_130210.csv  (127 filas limpias)
â”‚   â””â”€â”€ sensor_readings_silver_20251202_140521.csv  (55 filas limpias)
â”œâ”€â”€ weather/
â”‚   â””â”€â”€ weather_silver_20251202_130210.csv  (48 filas limpias)
â””â”€â”€ [otras tablas]/
    â””â”€â”€ ...
```

---

## ğŸ” VerificaciÃ³n de Datos

### Ver archivos en MinIO
```bash
mc ls myminio/meteo-bronze/
mc ls myminio/meteo-bronze/sensor_readings/
```

### Descargar archivo
```bash
mc cp myminio/meteo-bronze/sensor_readings/sensor_readings_bronce_*.csv ./
```

### Leer con Python
```python
import pandas as pd

df = pd.read_csv('sensor_readings_bronce_20251202_091647.csv')
print(f"Filas: {len(df)}")
print(df.head())
```

### Consultar tabla de control
```sql
SELECT * FROM etl_control;
```

**Resultado esperado:**
```
table_name     | last_extracted_value | last_extracted_at  | tracking_column
---------------|----------------------|--------------------|-----------------
sensor_readings| 1000                 | 2025-12-02 13:02   | id
weather        | 500                  | 2025-12-02 13:01   | measurement_id
```

---

## ğŸ› ï¸ SoluciÃ³n de Problemas

### Error: "El cliente 'mc' no estÃ¡ instalado"
```bash
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc
sudo mv mc /usr/local/bin/
```

### Error: "Connection refused" en PostgreSQL
```powershell
# Verificar credenciales
psql -h 10.202.50.50 -U postgres -d postgres

# Verificar variables de entorno
echo $env:PG_HOST
echo $env:PG_USER
```

### Error: "FallÃ³ la carga a MinIO"
```bash
# Verificar alias
mc alias list
mc alias set myminio http://localhost:9000 minioadmin minioadmin

# Verificar conectividad
mc ls myminio
```

### Error: "Table etl_control not found"
El sistema crea la tabla automÃ¡ticamente en la primera ejecuciÃ³n. Si no se crea:
```sql
CREATE TABLE etl_control (
    table_name VARCHAR(255) PRIMARY KEY,
    last_extracted_value VARCHAR(255),
    last_extracted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    tracking_column VARCHAR(255)
)
```

### No detecta columna de rastreo
Editar en `etl/table_inspector.py`:
```python
# Agregar candidatos personalizados
timestamp_candidates = ['created_at', 'updated_at', 'fecha', 'date', 'tu_columna']
```

---

## ğŸ“ˆ Ejemplo de EjecuciÃ³n Completa

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ Iniciando Sistema ETL Incremental
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š Base de datos: postgres@10.202.50.50
ğŸ—„ï¸  MinIO Bucket: meteo-bronze
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

--- INICIO DE BATCH: 2025-12-02 09:16:47 ---

Procesando tabla: sensor_readings
   ğŸ“Š Detectada columna: id (numÃ©rica)
   ğŸ” Ãšltimo valor: 900
   ğŸ“¦ Registros nuevos: 97
   ğŸ’¾ Guardando: sensor_readings_bronce_20251202_091647.csv
   âœ… Subido a Bronce
   ğŸ§¹ Limpiando...
   âœ… Duplicados eliminados: 97 â†’ 97
   âœ… Outliers reemplazados: 2
   âœ… Columnas eliminadas: 5
   âœ… Subido a Silver: sensor_readings_silver_20251202_091647.csv

Procesando tabla: weather
   ğŸ“Š Detectada columna: created_at (timestamp)
   ğŸ” Ãšltimo valor: 2025-12-02 08:00:00
   ğŸ“¦ Registros nuevos: 50
   ğŸ’¾ Guardando: weather_bronce_20251202_091647.csv
   âœ… Subido a Bronce
   ğŸ§¹ Limpiando...
   âœ… Duplicados eliminados: 50 â†’ 50
   âœ… Outliers reemplazados: 1
   âœ… Subido a Silver: weather_silver_20251202_091647.csv

ğŸ¯ RESUMEN: 147 registros nuevos en este batch.
â° PrÃ³xima ejecuciÃ³n: 09:21:47 (en 5 minutos)
```

---

## ğŸ“ PrÃ³ximos Pasos

- [ ] Agregar pruebas unitarias
- [ ] Implementar logging estructura (logging module)
- [ ] Agregar mÃ©tricas y monitoreo
- [ ] Crear CLI para administraciÃ³n
- [ ] Implementar re-intentos automÃ¡ticos
- [ ] Agregar alertas por errores

---

## ğŸ‘¤ InformaciÃ³n del Proyecto

- **Tipo**: Data Lake ETL
- **Arquitectura**: Modular, OOP, SOLID
- **Lenguaje**: Python 3.8+
- **Frameworks**: SQLAlchemy, Pandas, PySpark, MinIO
- **Bases de datos**: PostgreSQL, MinIO (Object Storage)

---

## ğŸ“– DocumentaciÃ³n TÃ©cnica

Este archivo consolida toda la documentaciÃ³n tÃ©cnica del proyecto. Todos los componentes estÃ¡n documentados con:
- Type hints completos
- Docstrings en mÃ©todos
- Ejemplos de uso
- Configuraciones recomendadas

Para preguntas especÃ­ficas sobre componentes individuales, consultar los archivos en `etl/` y `config/`.

---

**Ãšltima actualizaciÃ³n:** 2 de Diciembre de 2025  
**VersiÃ³n:** 2.0 (RefactorizaciÃ³n OOP Completa)
