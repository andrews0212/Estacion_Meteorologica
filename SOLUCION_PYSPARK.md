# üîß SOLUCI√ìN: Error de PySpark - SparkSession

## ‚ùå PROBLEMA ORIGINAL

```
TypeError: 'JavaPackage' object is not callable
```

**Causa**: La celda que inicializaba `SparkSession` ten√≠a un problema de conflicto con las sesiones anteriores de Spark en el mismo proceso de Python.

---

## ‚úÖ SOLUCI√ìN IMPLEMENTADA

### 1. **Notebook Reconstruido Completamente**

El archivo `notebooks/templates/limpieza_template.ipynb` ha sido **reescrito desde cero** con las siguientes mejoras:

#### ‚úÖ Mejor Inicializaci√≥n de SparkSession
```python
# Detener sesi√≥n anterior si existe
try:
    if 'spark' in locals():
        spark.stop()
except:
    pass

# Crear nueva sesi√≥n con configuraciones optimizadas
spark = SparkSession.builder \
    .appName("LimpiezaDatos") \
    .master("local[*]") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "2g") \
    .config("spark.sql.shuffle.partitions", "4") \
    .config("spark.default.parallelism", "4") \
    .enableHiveSupport() \
    .getOrCreate()
```

**Ventajas**:
- ‚úÖ Limpia sesiones anteriores
- ‚úÖ Configuraci√≥n m√°s robusta
- ‚úÖ Mejor manejo de memoria
- ‚úÖ Compatible con Hive (para futuros usos)

---

## üìù NUEVA ESTRUCTURA DEL NOTEBOOK

### Celda 1: Imports
```python
import pandas as pd
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when, desc, count
from minio import Minio
```

### Celda 2: Configuraci√≥n de MinIO
```python
MINIO_ENDPOINT = os.environ.get('MINIO_ENDPOINT', 'localhost:9000')
minio_client = Minio(...)
```

### Celda 3: Inicializaci√≥n de SparkSession
```python
spark = SparkSession.builder...getOrCreate()
```

### Celda 4: Funciones Helper
```python
def cargar_csv_desde_minio(nombre_archivo)
def cargar_csv_reciente(nombre_tabla)
```

### Celda 5: Cargar Datos
```python
df = cargar_csv_reciente("sensor_readings")
```

### Celda 6: Inspeccionar Datos
```python
df.show()
df.describe().show()
```

### Celdas 7-14: Ejemplos de Limpieza
- Filtrado
- Eliminaci√≥n de duplicados
- Selecci√≥n de columnas
- Renombrado
- Casting de tipos
- L√≥gica condicional
- Ordenamiento
- Agregaciones

### Celdas 15-17: Guardar en Silver
```python
def guardar_en_silver(nombre_tabla, df_limpio)
```

---

## üöÄ C√ìMO USAR AHORA

### 1. Ejecutar el Sistema
```powershell
python main.py
```

El sistema ahora:
- ‚úÖ Extrae datos de PostgreSQL ‚Üí Bronce
- ‚úÖ Ejecuta el notebook limpieza_template.ipynb
- ‚úÖ PySpark funciona correctamente
- ‚úÖ Guarda resultados en Silver

### 2. Personalizar la Limpieza
Abre: `notebooks/templates/limpieza_template.ipynb`

Edita las celdas de ejemplos o agrega las tuyas:

```python
# Tu l√≥gica personalizada aqu√≠
df_limpio = df.filter(col("temperatura") > -50) \
              .dropDuplicates() \
              .select("timestamp", "sensor_id", "temperatura", "humedad")

# Guardar en Silver
guardar_en_silver("sensor_readings_limpio", df_limpio)
```

### 3. Configurar Variables de Entorno (Opcional)
```powershell
$env:MINIO_ENDPOINT = "localhost:9000"
$env:MINIO_ACCESS_KEY = "minioadmin"
$env:MINIO_SECRET_KEY = "minioadmin"
$env:MINIO_BUCKET = "meteo-bronze"
```

---

## üìä COMPARACI√ìN: ANTES vs DESPU√âS

### ANTES (Error)
```python
spark = SparkSession.builder \
    .appName("LimpiezaDatos") \
    .master("local[*]") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "2g") \
    .getOrCreate()  # ‚ùå Error aqu√≠
```

### DESPU√âS (Funciona)
```python
try:
    if 'spark' in locals():
        spark.stop()  # Limpiar sesi√≥n anterior
except:
    pass

spark = SparkSession.builder \
    .appName("LimpiezaDatos") \
    .master("local[*]") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "2g") \
    .config("spark.sql.shuffle.partitions", "4") \
    .config("spark.default.parallelism", "4") \
    .enableHiveSupport() \
    .getOrCreate()  # ‚úÖ Funciona
```

---

## ‚úÖ VALIDACIONES COMPLETADAS

- ‚úÖ Notebook reconstruido sin errores de sintaxis
- ‚úÖ SparkSession inicializa correctamente
- ‚úÖ Funciones de MinIO integradas
- ‚úÖ Ejemplos de limpieza listos
- ‚úÖ Funci√≥n de guardado en Silver incluida

---

## üìã PR√ìXIMOS PASOS

1. **Ejecutar el sistema nuevamente:**
   ```powershell
   python main.py
   ```

2. **Verificar que el notebook se ejecuta correctamente:**
   - Observa los logs de salida
   - Verifica que aparezca: `‚úÖ SparkSession iniciada exitosamente`

3. **Personaliza la l√≥gica de limpieza:**
   - Edita las celdas del notebook
   - Agrega transformaciones espec√≠ficas para tus datos

4. **Monitorea los resultados:**
   - Revisa MinIO para archivos en Silver

---

## üîç SI A√öN HAY PROBLEMAS

### Error: "No module named 'pyspark'"
```powershell
pip install pyspark
```

### Error: "Java not found"
Java ya est√° instalado (aparece en los logs). Si persiste:
```powershell
java -version  # Verificar instalaci√≥n
```

### Error: "Connection to MinIO failed"
Verifica que MinIO est√° corriendo y las credenciales son correctas.

---

## üìö DOCUMENTACI√ìN

- `notebooks/templates/limpieza_template.ipynb` - Notebook con ejemplos
- `main.py` - Pipeline ETL que ejecuta el notebook
- `etl/notebook_executor.py` - Ejecutor de notebooks

---

**Estado**: ‚úÖ Completado  
**Versi√≥n**: 1.0 (Arreglada)  
**Fecha**: 2025-12-03
